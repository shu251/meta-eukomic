<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Meta-eukomic</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Meta-eukomic</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./main.html" rel="" target="" aria-current="page">
 <span class="menu-text">Main</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#meta-eukomic" id="toc-meta-eukomic" class="nav-link active" data-scroll-target="#meta-eukomic"><span class="header-section-number">1</span> Meta-eukomic</a>
  <ul class="collapse">
  <li><a href="#background-reading" id="toc-background-reading" class="nav-link" data-scroll-target="#background-reading"><span class="header-section-number">1.1</span> Background reading</a></li>
  <li><a href="#working-environment" id="toc-working-environment" class="nav-link" data-scroll-target="#working-environment"><span class="header-section-number">1.2</span> Working environment</a></li>
  </ul></li>
  <li><a href="#step-by-step" id="toc-step-by-step" class="nav-link" data-scroll-target="#step-by-step"><span class="header-section-number">2</span> Step-by-step</a>
  <ul class="collapse">
  <li><a href="#determine-assembly-groups" id="toc-determine-assembly-groups" class="nav-link" data-scroll-target="#determine-assembly-groups"><span class="header-section-number">2.1</span> 1. Determine assembly groups</a></li>
  <li><a href="#trim-qc" id="toc-trim-qc" class="nav-link" data-scroll-target="#trim-qc"><span class="header-section-number">2.2</span> 2. Trim &amp; QC</a></li>
  <li><a href="#remove-ribosomal-rna" id="toc-remove-ribosomal-rna" class="nav-link" data-scroll-target="#remove-ribosomal-rna"><span class="header-section-number">2.3</span> 3. Remove ribosomal RNA</a>
  <ul class="collapse">
  <li><a href="#run-sortmerna-optional" id="toc-run-sortmerna-optional" class="nav-link" data-scroll-target="#run-sortmerna-optional">Run SortMeRNA (<em>optional</em>)</a></li>
  </ul></li>
  <li><a href="#assembly" id="toc-assembly" class="nav-link" data-scroll-target="#assembly"><span class="header-section-number">2.4</span> 4. Assembly</a>
  <ul class="collapse">
  <li><a href="#megahit-assembly-1" id="toc-megahit-assembly-1" class="nav-link" data-scroll-target="#megahit-assembly-1">MEGAHIT (assembly 1)</a></li>
  <li><a href="#idba-tran-assembly-2" id="toc-idba-tran-assembly-2" class="nav-link" data-scroll-target="#idba-tran-assembly-2">IDBA-Tran (assembly 2)</a></li>
  </ul></li>
  <li><a href="#evaluate-assemblies" id="toc-evaluate-assemblies" class="nav-link" data-scroll-target="#evaluate-assemblies"><span class="header-section-number">2.5</span> 5. Evaluate assemblies</a>
  <ul class="collapse">
  <li><a href="#quast" id="toc-quast" class="nav-link" data-scroll-target="#quast">QUAST</a></li>
  </ul></li>
  <li><a href="#cluster-assembly-output-mmseqs2" id="toc-cluster-assembly-output-mmseqs2" class="nav-link" data-scroll-target="#cluster-assembly-output-mmseqs2"><span class="header-section-number">2.6</span> 6. Cluster assembly output (mmseqs2)</a>
  <ul class="collapse">
  <li><a href="#quast-new-combined-assembly" id="toc-quast-new-combined-assembly" class="nav-link" data-scroll-target="#quast-new-combined-assembly">6.1 QUAST new combined assembly</a></li>
  </ul></li>
  <li><a href="#transdecoder" id="toc-transdecoder" class="nav-link" data-scroll-target="#transdecoder"><span class="header-section-number">2.7</span> 7. Transdecoder</a>
  <ul class="collapse">
  <li><a href="#optional-mmseq2-part-ii" id="toc-optional-mmseq2-part-ii" class="nav-link" data-scroll-target="#optional-mmseq2-part-ii">7.1 (optional) MMSeq2 part II</a></li>
  </ul></li>
  <li><a href="#key-output-files" id="toc-key-output-files" class="nav-link" data-scroll-target="#key-output-files"><span class="header-section-number">2.8</span> 8. Key output files</a></li>
  <li><a href="#annotation" id="toc-annotation" class="nav-link" data-scroll-target="#annotation"><span class="header-section-number">2.9</span> 9. Annotation</a>
  <ul class="collapse">
  <li><a href="#marferret-diamond" id="toc-marferret-diamond" class="nav-link" data-scroll-target="#marferret-diamond">9.1 Marferret &amp; Diamond</a></li>
  </ul></li>
  <li><a href="#transcript-counts" id="toc-transcript-counts" class="nav-link" data-scroll-target="#transcript-counts"><span class="header-section-number">2.10</span> 10. Transcript counts</a></li>
  <li><a href="#compile-outputs" id="toc-compile-outputs" class="nav-link" data-scroll-target="#compile-outputs"><span class="header-section-number">2.11</span> 11. Compile outputs</a>
  <ul class="collapse">
  <li><a href="#transcipt-counts" id="toc-transcipt-counts" class="nav-link" data-scroll-target="#transcipt-counts">11.1 Transcipt counts</a></li>
  <li><a href="#get-tpms-annotation-information" id="toc-get-tpms-annotation-information" class="nav-link" data-scroll-target="#get-tpms-annotation-information">11.2 Get TPMs &amp; Annotation information</a></li>
  <li><a href="#reformat-for-hackathon" id="toc-reformat-for-hackathon" class="nav-link" data-scroll-target="#reformat-for-hackathon">11.3 Reformat for hackathon!</a></li>
  </ul></li>
  <li><a href="#metatranscriptome-run-information" id="toc-metatranscriptome-run-information" class="nav-link" data-scroll-target="#metatranscriptome-run-information"><span class="header-section-number">2.12</span> Metatranscriptome run information</a></li>
  </ul></li>
  <li><a href="#eukrhythmic" id="toc-eukrhythmic" class="nav-link" data-scroll-target="#eukrhythmic"><span class="header-section-number">3</span> eukrhythmic</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Meta-eukomic</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="meta-eukomic" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Meta-eukomic</h1>
<p><em>SKH</em> last updated August 2024</p>
<p>Location for raw files: <code>/scratch/group/hu-lab/meta-eukomics/raw-data</code> Individual R1 and R2 files are 2.9 and 2.7 G, respectively.</p>
<section id="background-reading" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="background-reading"><span class="header-section-number">1.1</span> Background reading</h2>
<ol type="1">
<li><p>Cohen NR, Alexander H, Krinos AI, Hu SK, Lampe RH. Marine Microeukaryote Metatranscriptomics: Sample Processing and Bioinformatic Workflow Recommendations for Ecological Applications. Frontiers in Marine Science 2022; 9.</p></li>
<li><p>Krinos AI, Cohen NR, Follows MJ, Alexander H. Reverse engineering environmental metatranscriptomes clarifies best practices for eukaryotic assembly. BMC Bioinformatics 2023; 24: 74.</p></li>
</ol>
</section>
<section id="working-environment" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="working-environment"><span class="header-section-number">1.2</span> Working environment</h2>
<p>High performance computer (HPC) hosted by my University. This is the TAMU HPRC.</p>
</section>
</section>
<section id="step-by-step" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Step-by-step</h1>
<section id="determine-assembly-groups" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="determine-assembly-groups"><span class="header-section-number">2.1</span> 1. Determine assembly groups</h2>
<p>When we have more than one sample, it is best to “group” samples for the assembly steps. Often this takes a few attempts and is a balance of an ideal plan vs.&nbsp;how much computational power you may have.</p>
</section>
<section id="trim-qc" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="trim-qc"><span class="header-section-number">2.2</span> 2. Trim &amp; QC</h2>
<p><em>Initial Fastqc</em></p>
<p>Code for slurm script run on the HPC to run fastqc (<code>fastqc.slurm</code>). For this set of samples, it took 10 minutes and used 290 MB. CPU used: 00:12:27.</p>
<pre><code># module load FastQC/0.11.9-Java-11

fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001.fastq.gz
fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_001.fastq.gz</code></pre>
<p>In order to look at the output <code>.html</code> files, they need to be opened locally.</p>
<pre><code>scp $HPRC-ADDRESS:/scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001_fastqc.html meta-eukomic/output-files/</code></pre>
<p>Then we need to trim the individual reads, removing any sequencing-based primers, etc. We can use the program, <a href="http://www.usadellab.org/cms/?page=trimmomatic">Trimmomatic</a> for this. R1 reads are forward and R2 are reverse. The Trimmomatic software requires input reads and then output trimmed and unpaired reads (the latter of which are discarded). Another input file required is a list of the possible primers and adapters from sequencing, <code>adapters-primers.fa</code>.</p>
<p>Slurm script, <code>trim_fastqc.slurm</code>. Below, trim parameter include:</p>
<ul>
<li><p>Remove adapters, found in <code>adapters-primers.fa</code></p></li>
<li><p>Remove leading low quality or N bases (below quality 3) (LEADING:3)</p></li>
<li><p>Remove trailing low quality or N bases (below quality 3) (TRAILING:3)</p></li>
<li><p>Scan the read with a 4-base wide sliding window, cutting when the average quality per base drops below 10 (SLIDINGWINDOW:4:10)</p></li>
<li><p>Drop reads shorter than 50 bases long (MINLEN:50)</p></li>
</ul>
<pre><code>module load Trimmomatic/0.39-Java-11

java -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar PE /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_001.fastq.gz  /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_unpaired.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_unpaired.fastq.gz ILLUMINACLIP:adapters-primers.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:10 MINLEN:50

# "$EBROOTTRIMMOMATIC/trimmomatic-0.39.jar" note that this is specific to the HPRC system we are using

echo "Trimmomtatic complete. Repeating fastqc"

module load FastQC/0.11.9-Java-11

fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz
fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz</code></pre>
<blockquote class="blockquote">
<p>The above trimming steps took 615 MB of memory and 2 hours.</p>
</blockquote>
</section>
<section id="remove-ribosomal-rna" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="remove-ribosomal-rna"><span class="header-section-number">2.3</span> 3. Remove ribosomal RNA</h2>
<p><a href="https://sortmerna.readthedocs.io/en/latest/installation.html">Sortmerna</a> installation guidelines and usage can be found here.</p>
<p>On the TAMU HPRC, this is where we needed to make a conda environment to run this.</p>
<pre><code># Load anaconda
module load Anaconda3/2022.05

# modify bioconda config for sortmeRNA
conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge
conda config --set channel_priority strict</code></pre>
<p>Search for sortmerna using conda:</p>
<pre><code>conda search sortmerna</code></pre>
<p>Create a conda environment specific for sortmerna, activate it, and install it.</p>
<pre><code>conda create --name sortmerna_env
conda activate sortmerna_env
conda install sortmerna</code></pre>
<p>Answer “yes” (<em>Y</em>) to installation questions. Now when you run SortMeRNA, you need to activate this conda environment and execute your code. The next step is to download the databases to use for this program.</p>
<section id="sortmerna-databases" class="level4">
<h4 class="anchored" data-anchor-id="sortmerna-databases">SortMeRNA databases</h4>
<p>Separately, you need to download the databases to “align” and check the sequences for ribosomal RNAs. See <code>sortmerna-db-build.slurm</code>.</p>
<p>Instructions for <a href="https://sortmerna.readthedocs.io/en/latest/databases.html">downloading version 4</a>:</p>
<pre><code># Move to the location you want your rRNA databases stored
cd /scratch/group/hu-lab/meta-eukomics/ 

# Download from github release 
wget https://github.com/biocore/sortmerna/releases/download/v4.3.4/database.tar.gz

# Make new directory for this and un-zip downloaded file
mkdir rRNA_databases_v4
tar -xvf database.tar.gz -C rRNA_databases_v4</code></pre>
</section>
<section id="run-sortmerna-optional" class="level3">
<h3 class="anchored" data-anchor-id="run-sortmerna-optional">Run SortMeRNA (<em>optional</em>)</h3>
<p>In your slurm script, activate conda, and then the sortmerna environment (<code>sortmeRNA.slurm</code>):</p>
<pre><code># Load anaconda
module load Anaconda3/2022.05
conda activate sortmerna_env

mkdir /scratch/group/hu-lab/meta-eukomics/rRNA-sort

sortmerna -ref /scratch/group/hu-lab/meta-eukomics/rRNA_databases_v4/smr_v4.3_sensitive_db.fasta \
-reads /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz \
-reads /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \
-workdir /scratch/group/hu-lab/meta-eukomics/rRNA-sort/ -aligned rRNA-aligned -other non-rRNA
-fastx --paired_in --out2 --threads $SLURM_CPUS_PER_TASK</code></pre>
<p><code>-paired_in</code>: The option ‘paired_in’ is optimal for users who want all reads in the other.fasta file to be non-rRNA. However, there are small chances that reads which are non-rRNA will also be put into the aligned.fasta file.</p>
<p>Since the SortmeRNA tool is optimized to take things that are aligned with the rRNA databases and put them in a file called “aligned”, then we need to use the <code>other.fasta</code> output file. The argument for this is <code>-out2</code></p>
<p>Necessary flags for retaining the non-rRNA aligned reads and outputting them as separate R1 and R2 files: <code>-other</code>, <code>-fastx</code>, <code>--paired_in</code>, and <code>--out2</code>. To learn more about this check out this thread: <em>How do I properly run sortmerna?</em> https://github.com/sortmerna/sortmerna/issues/333</p>
<blockquote class="blockquote">
<p>This was run with 32 threads and 1 node. It took 2 hours 45 minutes and used just over 16 GB of memory.</p>
</blockquote>
<blockquote class="blockquote">
<p>The total number of reads that aligned to the rRNA databases was pretty small. I am planning to not use the Sorted reads, as there are some issue with the program. Will look for another way to sort reads.</p>
</blockquote>
</section>
</section>
<section id="assembly" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="assembly"><span class="header-section-number">2.4</span> 4. Assembly</h2>
<p>The next step is to take all the trimmed reads and bring them together to make longer, more continuous sequences, called <em>contigs</em>. Here, we will use two assemblers and combine the results. Each one is built slightly differently.</p>
<section id="megahit-assembly-1" class="level3">
<h3 class="anchored" data-anchor-id="megahit-assembly-1">MEGAHIT (assembly 1)</h3>
<p>We will first use <a href="https://github.com/voutcn/megahit">megahit</a>. To save the assemblies separately, make a new assembly output file in your working <code>scratch</code> space. <code>mkdir /scratch/group/hu-lab/meta-eukomics/assembly</code></p>
<p>The megahit command below, outputs contigs in the new <code>assembly</code> directory, only keeps reads longer than 100 bps, and uses the megahit preset for lots of diversity in a sample (<em>meta-large</em>).</p>
<p>Megahit uses multiple k-mer strategy, and we can set the min and max k. In order to reduce the complexity of the <em>de Bruijin</em> graph, a kmin size of 25 and higher (like 27) is better.</p>
<p>See slurm script: <code>megahit-assembly.slurm</code></p>
<pre><code>module load GCCcore/11.2.0
module load MEGAHIT/1.2.9

megahit -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz -o /scratch/group/hu-lab/meta-eukomics/assembly/ --min-contig-len 1000 --presets meta-large --num-cpu-threads 32</code></pre>
<blockquote class="blockquote">
<p>With the above settings, megahit recovered 31,331 contigs, total 44610184 bp, min 1000 bp, max 10674 bp, avg 1423 bp, N50 1391 bp. And this took about <em>10 hours</em>.</p>
</blockquote>
<blockquote class="blockquote">
<p>On the HPC, this was run on 1 node, 4 cores per node, and it used 18.5 GBs of memory.</p>
</blockquote>
<p>Megahit assembly location: <code>/scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa</code></p>
<p><em>Optional</em>: Visualize your megahit assembly</p>
<p>When megahit assembly is complete, use this option to visualize it: https://github.com/voutcn/megahit/wiki/Visualizing-MEGAHIT’s-contig-graph</p>
</section>
<section id="idba-tran-assembly-2" class="level3">
<h3 class="anchored" data-anchor-id="idba-tran-assembly-2">IDBA-Tran (assembly 2)</h3>
<p><a href="https://i.cs.hku.hk/~alse/hkubrg/projects/idba_tran/index.html">IDBA-tran</a> is another <em>de novo</em> assembler. Uses local assembly to reconstruct missing kmers in low-expressed transcripts.</p>
<p>See script: <code>idba-assembly.slurm</code> to run assembly with minimum kmer at 20 and max kmer at 50 with a 5 step increment of kmer.</p>
<pre><code>echo "unzip files"
gunzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R*_trimmed.fastq.gz

module load GCC/8.2.0-2.31.1 
module load IDBA-UD/1.1.3

# Convert fastq R1 and R2 files into a single 'interleaved` fastq files
fq2fa --merge --filter /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq /scratch/group/hu-lab/meta-eukomics/assembly/merged-PE-for-idba.fa

# Run assembly
idba_tran -r /scratch/group/hu-lab/meta-eukomics/assembly/merged-PE-for-idba.fa -o /scratch/group/hu-lab/meta-eukomics/assembly/idba-out --mink 20 --maxk 50 --step 5 --num_threads 16

# Make sure fastq files are re-zipped:
gzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq
gzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq</code></pre>
<blockquote class="blockquote">
<p>Using 8 cores, the IDBA-tran assembly took about 23 hours and used 130 GB of memory.</p>
</blockquote>
<p>The <em>IDBA-tran output</em> includes separation by k-mer length. So there are multiple “contig-X.fa” files. Where <code>contig-25.fa</code> is the output contigs at k-mer = 25. The IDBA program determines which one is best and then puts this into the final <code>contig.fa</code> file. Output: <code>/scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa</code></p>
</section>
</section>
<section id="evaluate-assemblies" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="evaluate-assemblies"><span class="header-section-number">2.5</span> 5. Evaluate assemblies</h2>
<section id="quast" class="level3">
<h3 class="anchored" data-anchor-id="quast">QUAST</h3>
<p>QUAST stands for <em>QUality ASsessment Tool</em> and it is a tool for evaluating assemblies. Not all tools for evaluating assemblies will work, as most are built for metagenomics or require a reference genome. In this case, we do not have a reference genome.</p>
<p><em>First for the IDBA output</em> <code>quast-idba.slurm</code>:</p>
<pre><code>module load GCC/9.3.0
module load OpenMPI/4.0.3
module load QUAST/5.0.2-Python-3.8.2

quast.py /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa \
        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \
        -o /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/ \
        --threads $SLURM_CPUS_PER_TASK</code></pre>
<blockquote class="blockquote">
<p>This was run on 1 node with 16 cores. It used 3.5 GB of memory in about 1 hour. 6:15 CPUs used.</p>
</blockquote>
<p><em>Repeat for the megahit output</em> <code>quast-megahit.slurm</code>:</p>
<pre><code>module load GCC/9.3.0
module load OpenMPI/4.0.3
module load QUAST/5.0.2-Python-3.8.2

quast.py /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa \
        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \
        -o /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/ \
        --threads $SLURM_CPUS_PER_TASK</code></pre>
<blockquote class="blockquote">
<p>At 16 cores (1 node), this took about 1 hour at 3 GB of memory.</p>
</blockquote>
<section id="interpret-quast" class="level4">
<h4 class="anchored" data-anchor-id="interpret-quast">Interpret QUAST</h4>
<p>Download files locally from:</p>
<ul>
<li>PDF files: <code>meta-eukomics/assembly/*-out/basic_stats/*.pdf</code></li>
<li>Use an ICARUS html viewer: <code>meta-eukomics/assembly/*-out/icarus*</code></li>
<li>Basic read stats: <code>meta-eukomics/assembly/*-out/reads_stats/reads_report.tsv</code></li>
</ul>
<section id="example-output-from-quast" class="level5">
<h5 class="anchored" data-anchor-id="example-output-from-quast">Example output from QUAST</h5>
<p><em>idba output</em></p>
<pre><code>Assembly                    contig   
# contigs (&gt;= 0 bp)         892652   
# contigs (&gt;= 1000 bp)      13948    
# contigs (&gt;= 5000 bp)      16       
# contigs (&gt;= 10000 bp)     0        
# contigs (&gt;= 25000 bp)     0        
# contigs (&gt;= 50000 bp)     0        
Total length (&gt;= 0 bp)      310591507
Total length (&gt;= 1000 bp)   19165345 
Total length (&gt;= 5000 bp)   101378   
Total length (&gt;= 10000 bp)  0        
Total length (&gt;= 25000 bp)  0        
Total length (&gt;= 50000 bp)  0        
# contigs                   105801   
Largest contig              9483     
Total length                78684450 
GC (%)                      53.19    
N50                         714      
N75                         581      
L50                         38334    
L75                         69112    
# total reads               110011298
# left                      54322593 
# right                     54322593 
Mapped (%)                  28.29    
Properly paired (%)         19.43    
Avg. coverage depth         27       
Coverage &gt;= 1x (%)          99.98    
# N's per 100 kbp           0.00     </code></pre>
<p><em>megahit output</em></p>
<pre><code>Assembly                    final.contigs
# contigs (&gt;= 0 bp)         31331        
# contigs (&gt;= 1000 bp)      31331        
# contigs (&gt;= 5000 bp)      27           
# contigs (&gt;= 10000 bp)     2            
# contigs (&gt;= 25000 bp)     0            
# contigs (&gt;= 50000 bp)     0            
Total length (&gt;= 0 bp)      44610184     
Total length (&gt;= 1000 bp)   44610184     
Total length (&gt;= 5000 bp)   176055       
Total length (&gt;= 10000 bp)  21295        
Total length (&gt;= 25000 bp)  0            
Total length (&gt;= 50000 bp)  0            
# contigs                   31331        
Largest contig              10674        
Total length                44610184     
GC (%)                      53.78        
N50                         1391         
N75                         1152         
L50                         12043        
L75                         20904        
# total reads               108929544    
# left                      54322593     
# right                     54322593     
Mapped (%)                  24.47        
Properly paired (%)         18.5         
Avg. coverage depth         47           
Coverage &gt;= 1x (%)          99.98        
# N's per 100 kbp           0.00         </code></pre>
<p>Notes on comparison:</p>
<p>IDBA output a lot more contigs, but they are shorter. Megahit has many fewer (31,331 / 105,801) of the total contigs. However, contigs over 1000 bps from IDBA drops to only 13K. Demonstrating that most of them are between 500 - 1000 bps (because the program only reports contigs greater than 500 bps). Megahit, on the otherhand, has over 31k contigs that are greater than 1000 bps in length. For super long contigs, we get 27 from megahit and only 16 from idba (&gt;5K bps).</p>
<p>As a result, we do get more of the original transcripts mapping to the IDBA output. but the average coverage is 27. Megahit has a few points fewer for % mapped, but the average coverage depth is 47.</p>
<p>These assemblies can be combined below.</p>
</section>
</section>
</section>
</section>
<section id="cluster-assembly-output-mmseqs2" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="cluster-assembly-output-mmseqs2"><span class="header-section-number">2.6</span> 6. Cluster assembly output (mmseqs2)</h2>
<p>Because we have outputs from two separate assemblies, we can use a program to “cluster” the output contigs together. The clustering / merging of contigs is based on sequence similarity, so we need to include a similarity parameter that is kind of arbitrary.</p>
<p>We will use <a href="https://github.com/soedinglab/MMseqs2">mmseqs2</a> and try this at 99% similarity. MMseq stands for “Many-against-Many sequence searching”</p>
<p>First, the output contig files from IDBA and Megahit are combined: <code>cluster-mmseqs2.slurm</code></p>
<pre><code># Precursor load to use MMseqs2 on HPRC
module load GCC/10.2.0
module load OpenMPI/4.0.5
module load MMseqs2/13-45111

mkdir /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly

cat /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa &gt; /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta


# Use the 'easy-linclust' option

mmseqs easy-linclust /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/clusterRes /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/tmp --threads=$SLURM_CPUS_PER_TASK
</code></pre>
<p>If you’re working with a massive amount of data, this is a good place to try reducing the percent identity with mmseqs down to 99% or 98%.</p>
<blockquote class="blockquote">
<p>32 cores (1 node), this took just under 1 hour and 1.3 GB of memory.</p>
</blockquote>
<section id="quast-new-combined-assembly" class="level3">
<h3 class="anchored" data-anchor-id="quast-new-combined-assembly">6.1 QUAST new combined assembly</h3>
<p>Repeat assembly evaluation with quast (<code>quast-combined.slurm</code>)</p>
<pre><code>quast.py /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta \
        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \
        -o /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/ \
        --threads $SLURM_CPUS_PER_TASK</code></pre>
<p>Now, with a combined assembly we get a better deal with our contigs. We have more like 137,132 contigs. This is more than both IDBA and megahit, but we are now getting more than 45K greater than 1000 bp, and 43 greater than 5K bps. And now, the percent mapped from original reads is higher at 31%, but our average coverage depth drops to 21. This is fine because we can map more reads to our assemblies.</p>
</section>
</section>
<section id="transdecoder" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="transdecoder"><span class="header-section-number">2.7</span> 7. Transdecoder</h2>
<p>From the combined assemblies, we need to extract the long open reading frames (ORFs). ORFs will be identified that have at least 100 aminos acids. Then we also follow this with predicting the likely coding regions so we can continue with protein annotation.</p>
<p><code>transdecoder.slurm</code>:</p>
<pre><code>module load GCC/11.3.0
module load TransDecoder/5.5.0

#extract the long open reading frames
TransDecoder.LongOrfs -t /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta --output_dir /scratch/group/hu-lab/meta-eukomics/predictions/

# predict the likely coding regions
TransDecoder.Predict -t /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta --output_dir /scratch/group/hu-lab/meta-eukomics/predictions/</code></pre>
<p>Output files: <code>/scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta.transdecoder.*</code></p>
<blockquote class="blockquote">
<p>At 16 cores (1 node), job took 5.5 GB of memory and 1 hour.</p>
</blockquote>
<section id="optional-mmseq2-part-ii" class="level3">
<h3 class="anchored" data-anchor-id="optional-mmseq2-part-ii">7.1 (optional) MMSeq2 part II</h3>
<p>At this point, if you have a LOT of samples and large amounts of data, a repeat clustering of the proteins will help reduce the amount of data you’re working with.</p>
</section>
</section>
<section id="key-output-files" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="key-output-files"><span class="header-section-number">2.8</span> 8. Key output files</h2>
<p>At this point, you have assembled, quality checked, and predicted proteins for all your metatranscriptomes.</p>
<ul>
<li><p>Assembled contigs: <code>/scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/clusterRes_rep_seq.fasta</code></p></li>
<li><p>Predicted proteins: <code>/scratch/group/hu-lab/meta-eukomics/predictions</code> see files ending in .gff3 and .pep</p></li>
<li><p><code>/scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta.transdecoder.*</code></p></li>
</ul>
<p><em>Next steps</em>: annotate above files, based on predicted proteins or the contigs and determine transcript abundance by mapping the original trimmed fastq reads back onto these contigs.</p>
</section>
<section id="annotation" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="annotation"><span class="header-section-number">2.9</span> 9. Annotation</h2>
<p>The goal of the below steps is to match assembled reads with taxonomy and protein databases.</p>
<section id="marferret-diamond" class="level3">
<h3 class="anchored" data-anchor-id="marferret-diamond">9.1 Marferret &amp; Diamond</h3>
<p>For taxonomic annotation, using <a href="https://github.com/armbrustlab/marferret">MarFERReT</a></p>
<p>For this we will use <a href="https://github.com/bbuchfink/diamond">Diamond</a>. This is a really fast tool for querying nucleotide or protein sequences again a database. You need to first make a diamond database (<code>.dmnd</code>), and then use <code>blastp</code> or something to</p>
<p>To use the Marferrt resource, we need to query our combined assembly and predicted protein IDs with the Marferret this with diamond.</p>
<p>In order to run Diamond (or any similar blast-like program), we need to consider a few variables &amp; terms.</p>
<ul>
<li><p><em>e-value</em> (expectation value): This is the number of hits that could be found by chance. So an e-value of 50, means up to 50 of the matches (or hits) in your results could be a result of chance. Therefore, lower e-values mean you will get better matches, or matches of better quality. Generally, these programs may have e-value defaults of 10, which may be helpful for looking at all possible results. But an e-value of 0.01 would be better to use to look for good matches. There is a formula for how we calcuate e-values, and it depends on the size of the query sequences and the databases.</p></li>
<li><p><em>Bit score</em>: This is the result of a log2 scaled and normalized score of the number of matches that could be found by chance based on the database size.</p></li>
</ul>
<p>Diamond default e-value is 0.001, I am changing mine to 0.0001. And I’m using the <code>--sensitive</code> setting which finds significant matches with &gt;50 bits for fragments that are between 30-40 aa.</p>
<pre><code>module load GCC/11.2.0
module load DIAMOND/2.0.15

diamond blastp --threads $SLURM_CPUS_PER_TASK --query /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta.transdecoder.pep --db /scratch/group/hu-lab/marferret/data/MarFERReT.v1.1.1.dmnd -o /scratch/group/hu-lab/meta-eukomics/annotation/meta-eukomic_marferret_07082024.txt --sensitive --evalue 0.0001 --max-target-seqs 10 --outfmt 6 qseqid sseqid sallseqid evalue bitscore qlen slen</code></pre>
<blockquote class="blockquote">
<p>With 32 cores (1 node), this took 20 minutes and 10 GB of memory.</p>
</blockquote>
</section>
</section>
<section id="transcript-counts" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="transcript-counts"><span class="header-section-number">2.10</span> 10. Transcript counts</h2>
<p>For determining “gene expression”, we estimate this from the number of transcripts (sequenced reads) that map onto your assembled reads. We will use <a href="https://combine-lab.github.io/salmon/#:~:text=Salmon%20is%20a%20tool%20for,and%20while%20using%20little%20memory.">salmon</a>.</p>
<p>First we need to index your transcripts - salmon uses a quasi-map approach to quantify the reads.</p>
<pre><code>module load GCC/11.2.0
module load OpenMPI/4.1.1
module load Salmon/1.7.0

mkdir /scratch/group/hu-lab/meta-eukomics/salmon-quant

salmon index -t /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/clusterRes_rep_seq.fasta -i /scratch/group/hu-lab/meta-eukomics/salmon-quant/ -p $SLURM_CPUS_PER_TASK</code></pre>
<blockquote class="blockquote">
<p>Indexing this data took 45 minutes (32 cores, 1 node) and 1.2 GB of memory</p>
</blockquote>
<pre><code>salmon quant -i /scratch/group/hu-lab/meta-eukomics/salmon-quant/ -l A \
         -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz \
         -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \
         -p $SLURM_CPUS_PER_TASK --validateMappings -o /scratch/group/hu-lab/meta-eukomics/salmon-quant/quant</code></pre>
<blockquote class="blockquote">
<p>At 32 cores (1 node), transcript counts took 3.5 hours and 4.2 GB of memory.</p>
</blockquote>
<p>Read more here, especially on how to loop through samples: https://combine-lab.github.io/salmon/getting_started/#indexing-txome</p>
</section>
<section id="compile-outputs" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="compile-outputs"><span class="header-section-number">2.11</span> 11. Compile outputs</h2>
<ul>
<li><p>Annotation from marferret: <code>/scratch/group/hu-lab/meta-eukomics/annotation/meta-eukomic_marferret_07082024.txt</code> Column 1 is the contig ID name (qseqid) and the second ID is the match ID from the database (sseqid). These two columns need to be put into a new dataframe and called “TRANSCRIPTID” and “GENEID”</p></li>
<li><p>For the GENEIDs, the “mftXXXXXXXXX” names correspond to pfam IDs in: <code>/scratch/group/hu-lab/marferret/data/MarFERReT.v1.1.1.best_pfam_annotations.csv.gz</code></p></li>
</ul>
<p>** Use <code>MarFERReT.v1.1.1.taxonomies.tab.gz</code> to get the <em>tax id</em> and then line this up with <code>MarFERReT.v1.1.1.metadata.csv</code> to get the actual taxonomy.</p>
<p>See <code>scripts/compile-metat-results.R</code>. This script will output an R object called <code>tx_gene_KEY</code>.</p>
<section id="transcipt-counts" class="level3">
<h3 class="anchored" data-anchor-id="transcipt-counts">11.1 Transcipt counts</h3>
<p>For obtaining transcript-level estimates from the salmon count files, we need to use the R library <code>tximport</code>. Review <a href="https://github.com/thelovelab/tximport?tab=readme-ov-file">the manual here</a>.</p>
<p>Salmon output should be <code>/meta-eukomics/salmon-quant/quant/quant.sf</code></p>
<p>From the <code>compile-metat-results.R</code> code, you can import this <code>tx_gene_KEY</code> object to use in the <code>tximport</code> estimation of TPMs. First, you need to run the command <code>tximport</code>.</p>
<p>This should output a <em>txi</em> object called <code>txi_metat</code> and then you can create a paired sample table.</p>
<p>See the Rscript <code>scripts/tximport_run.R</code></p>
<pre><code>## Example:
# library(tximport)
# txi &lt;- tximport::tximport(files, type = "salmon", tx2gene = tx2gene_in)</code></pre>
</section>
<section id="get-tpms-annotation-information" class="level3">
<h3 class="anchored" data-anchor-id="get-tpms-annotation-information">11.2 Get TPMs &amp; Annotation information</h3>
<p>See <code>scripts/format-output-tables.R</code>. This takes the txi objects and uses the command <code>makeCountsFromAbundance()</code> to generate a TPM file that represents the transcript-length corrected estimates.</p>
<p>Then the script imports the annotation file, merges it with the count information to create a large R object with TPMs and annotation information.</p>
</section>
<section id="reformat-for-hackathon" class="level3">
<h3 class="anchored" data-anchor-id="reformat-for-hackathon">11.3 Reformat for hackathon!</h3>
<pre><code>load("/scratch/group/hu-lab/meta-eukomics/counts_metat_df_annot.RData", verbose = TRUE)
glimpse(counts_metat_df_annot)</code></pre>
</section>
</section>
<section id="metatranscriptome-run-information" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="metatranscriptome-run-information"><span class="header-section-number">2.12</span> Metatranscriptome run information</h2>
<table class="table">
<thead>
<tr class="header">
<th>Software</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Fastqc</td>
<td>0.11.9</td>
</tr>
<tr class="even">
<td>Trimmomatic</td>
<td>0.39</td>
</tr>
<tr class="odd">
<td>SortMeRNA</td>
<td>4.3.7</td>
</tr>
<tr class="even">
<td>megahit</td>
<td>1.2.9</td>
</tr>
<tr class="odd">
<td>IDBA-Tran</td>
<td>1.1.3</td>
</tr>
<tr class="even">
<td>quast</td>
<td>5.0.2</td>
</tr>
<tr class="odd">
<td>mmseqs2</td>
<td>13-45111</td>
</tr>
<tr class="even">
<td>TransDecoder</td>
<td>5.5.0</td>
</tr>
<tr class="odd">
<td>Salmon</td>
<td>1.7.0</td>
</tr>
<tr class="even">
<td>Diamond</td>
<td>2.0.15</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
<section id="citations" class="level4">
<h4 class="anchored" data-anchor-id="citations">Citations</h4>
<ul>
<li><p>[fastqc]</p></li>
<li><p>[trimmomatic]</p></li>
<li><p>SortMeRNA: Kopylova E., Noe L. and Touzet H., “SortMeRNA: Fast and accurate filtering of ribosomal RNAs in metatranscriptomic data”, Bioinformatics (2012), doi: 10.1093/bioinformatics/bts611.</p></li>
<li><p>[megahit]</p></li>
<li><p><a href="https://academic.oup.com/bioinformatics/article/29/13/i326/191893">IDBA-Tran</a></p></li>
<li><p>Salmon: Patro, R., Duggal, G., Love, M. I., Irizarry, R. A., &amp; Kingsford, C. (2017). Salmon provides fast and bias-aware quantification of transcript expression. Nature Methods.</p></li>
<li><p>QUAST: Gurevich A, Saveliev V, Vyahhi N, Tesler G. QUAST: quality assessment tool for genome assemblies. Bioinformatics. 2013;29: 1072 1075. doi:10.1093/bioinformatics/btt086 , https://www.ncbi.nlm.nih.gov/pubmed/23422339</p></li>
</ul>
</section>
</section>
</section>
<section id="eukrhythmic" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> eukrhythmic</h1>
<p>Guidelines and notes on running the same set of samples through the <a href="https://eukrhythmic.readthedocs.io/en/latest/index.html">eukrhythmic pipeline</a>. Running this on the TAMU HPRC with a conda environment.</p>
<p>First create a conda environment specific for eukrhythmic. <a href="https://docs.conda.io/projects/conda/en/4.6.1/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands">Learn more about how to manage these environments here.</a></p>
<pre><code>conda create -n eukrhythmic

# Activate environment
conda activate eukrhythmic

# Use HPRC system to ensure newest version of available Python is loaded
&gt; (eukrhythmic) module load GCCcore/12.3.0
&gt; (eukrhythmic) module load Python/3.11.3</code></pre>
<p>To check what version of python you are automatically running, use <code>python --version</code>.</p>
<ul>
<li>I could not get mamba configured correctly?</li>
</ul>
<pre><code>&gt; (eukrhythmic) conda install conda-forge::pyyaml
&gt; (eukrhythmic) conda install -c conda-forge python pandas

# Install snakemake, but use mamba
&gt; (eukrhythmic) conda install -c conda-forge mamba

mamba install -c conda-forge -c bioconda snakemake</code></pre>
<p>To run eukrhythmic, activate the environment: <code>conda activate eukrhythmic</code>.</p>
<pre><code></code></pre>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb26" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb26-1"><a href="#cb26-1"></a><span class="co">---</span></span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="an">title:</span><span class="co"> "Meta-eukomic"</span></span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="an">format:</span></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="co">  html:</span></span>
<span id="cb26-5"><a href="#cb26-5"></a><span class="co">    toc: true</span></span>
<span id="cb26-6"><a href="#cb26-6"></a><span class="co">    toc-location: left</span></span>
<span id="cb26-7"><a href="#cb26-7"></a><span class="co">    number-sections: true</span></span>
<span id="cb26-8"><a href="#cb26-8"></a><span class="co">    number-depth: 2</span></span>
<span id="cb26-9"><a href="#cb26-9"></a><span class="an">editor:</span><span class="co"> visual</span></span>
<span id="cb26-10"><a href="#cb26-10"></a><span class="co">---</span></span>
<span id="cb26-11"><a href="#cb26-11"></a></span>
<span id="cb26-12"><a href="#cb26-12"></a><span class="fu"># Meta-eukomic</span></span>
<span id="cb26-13"><a href="#cb26-13"></a></span>
<span id="cb26-14"><a href="#cb26-14"></a>*SKH* last updated August 2024</span>
<span id="cb26-15"><a href="#cb26-15"></a></span>
<span id="cb26-16"><a href="#cb26-16"></a>Location for raw files: <span class="in">`/scratch/group/hu-lab/meta-eukomics/raw-data`</span> Individual R1 and R2 files are 2.9 and 2.7 G, respectively.</span>
<span id="cb26-17"><a href="#cb26-17"></a></span>
<span id="cb26-18"><a href="#cb26-18"></a><span class="fu">## Background reading</span></span>
<span id="cb26-19"><a href="#cb26-19"></a></span>
<span id="cb26-20"><a href="#cb26-20"></a><span class="ss">1.  </span>Cohen NR, Alexander H, Krinos AI, Hu SK, Lampe RH. Marine Microeukaryote Metatranscriptomics: Sample Processing and Bioinformatic Workflow Recommendations for Ecological Applications. Frontiers in Marine Science 2022; 9.</span>
<span id="cb26-21"><a href="#cb26-21"></a></span>
<span id="cb26-22"><a href="#cb26-22"></a><span class="ss">2.  </span>Krinos AI, Cohen NR, Follows MJ, Alexander H. Reverse engineering environmental metatranscriptomes clarifies best practices for eukaryotic assembly. BMC Bioinformatics 2023; 24: 74.</span>
<span id="cb26-23"><a href="#cb26-23"></a></span>
<span id="cb26-24"><a href="#cb26-24"></a><span class="fu">## Working environment</span></span>
<span id="cb26-25"><a href="#cb26-25"></a></span>
<span id="cb26-26"><a href="#cb26-26"></a>High performance computer (HPC) hosted by my University. This is the TAMU HPRC.</span>
<span id="cb26-27"><a href="#cb26-27"></a></span>
<span id="cb26-28"><a href="#cb26-28"></a><span class="fu"># Step-by-step</span></span>
<span id="cb26-29"><a href="#cb26-29"></a></span>
<span id="cb26-30"><a href="#cb26-30"></a><span class="fu">## 1. Determine assembly groups</span></span>
<span id="cb26-31"><a href="#cb26-31"></a></span>
<span id="cb26-32"><a href="#cb26-32"></a>When we have more than one sample, it is best to "group" samples for the assembly steps. Often this takes a few attempts and is a balance of an ideal plan vs. how much computational power you may have.</span>
<span id="cb26-33"><a href="#cb26-33"></a></span>
<span id="cb26-34"><a href="#cb26-34"></a><span class="fu">## 2. Trim &amp; QC</span></span>
<span id="cb26-35"><a href="#cb26-35"></a></span>
<span id="cb26-36"><a href="#cb26-36"></a>*Initial Fastqc*</span>
<span id="cb26-37"><a href="#cb26-37"></a></span>
<span id="cb26-38"><a href="#cb26-38"></a>Code for slurm script run on the HPC to run fastqc (<span class="in">`fastqc.slurm`</span>). For this set of samples, it took 10 minutes and used 290 MB. CPU used: 00:12:27.</span>
<span id="cb26-39"><a href="#cb26-39"></a></span>
<span id="cb26-40"><a href="#cb26-40"></a><span class="in">```</span></span>
<span id="cb26-41"><a href="#cb26-41"></a><span class="in"># module load FastQC/0.11.9-Java-11</span></span>
<span id="cb26-42"><a href="#cb26-42"></a></span>
<span id="cb26-43"><a href="#cb26-43"></a><span class="in">fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001.fastq.gz</span></span>
<span id="cb26-44"><a href="#cb26-44"></a><span class="in">fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_001.fastq.gz</span></span>
<span id="cb26-45"><a href="#cb26-45"></a><span class="in">```</span></span>
<span id="cb26-46"><a href="#cb26-46"></a></span>
<span id="cb26-47"><a href="#cb26-47"></a>In order to look at the output <span class="in">`.html`</span> files, they need to be opened locally.</span>
<span id="cb26-48"><a href="#cb26-48"></a></span>
<span id="cb26-49"><a href="#cb26-49"></a><span class="in">```</span></span>
<span id="cb26-50"><a href="#cb26-50"></a><span class="in">scp $HPRC-ADDRESS:/scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001_fastqc.html meta-eukomic/output-files/</span></span>
<span id="cb26-51"><a href="#cb26-51"></a><span class="in">```</span></span>
<span id="cb26-52"><a href="#cb26-52"></a></span>
<span id="cb26-53"><a href="#cb26-53"></a>Then we need to trim the individual reads, removing any sequencing-based primers, etc. We can use the program, <span class="co">[</span><span class="ot">Trimmomatic</span><span class="co">](http://www.usadellab.org/cms/?page=trimmomatic)</span> for this. R1 reads are forward and R2 are reverse. The Trimmomatic software requires input reads and then output trimmed and unpaired reads (the latter of which are discarded). Another input file required is a list of the possible primers and adapters from sequencing, <span class="in">`adapters-primers.fa`</span>.</span>
<span id="cb26-54"><a href="#cb26-54"></a></span>
<span id="cb26-55"><a href="#cb26-55"></a>Slurm script, <span class="in">`trim_fastqc.slurm`</span>. Below, trim parameter include:</span>
<span id="cb26-56"><a href="#cb26-56"></a></span>
<span id="cb26-57"><a href="#cb26-57"></a><span class="ss">-   </span>Remove adapters, found in <span class="in">`adapters-primers.fa`</span></span>
<span id="cb26-58"><a href="#cb26-58"></a></span>
<span id="cb26-59"><a href="#cb26-59"></a><span class="ss">-   </span>Remove leading low quality or N bases (below quality 3) (LEADING:3)</span>
<span id="cb26-60"><a href="#cb26-60"></a></span>
<span id="cb26-61"><a href="#cb26-61"></a><span class="ss">-   </span>Remove trailing low quality or N bases (below quality 3) (TRAILING:3)</span>
<span id="cb26-62"><a href="#cb26-62"></a></span>
<span id="cb26-63"><a href="#cb26-63"></a><span class="ss">-   </span>Scan the read with a 4-base wide sliding window, cutting when the average quality per base drops below 10 (SLIDINGWINDOW:4:10)</span>
<span id="cb26-64"><a href="#cb26-64"></a></span>
<span id="cb26-65"><a href="#cb26-65"></a><span class="ss">-   </span>Drop reads shorter than 50 bases long (MINLEN:50)</span>
<span id="cb26-66"><a href="#cb26-66"></a></span>
<span id="cb26-67"><a href="#cb26-67"></a><span class="in">```</span></span>
<span id="cb26-68"><a href="#cb26-68"></a><span class="in">module load Trimmomatic/0.39-Java-11</span></span>
<span id="cb26-69"><a href="#cb26-69"></a></span>
<span id="cb26-70"><a href="#cb26-70"></a><span class="in">java -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar PE /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_001.fastq.gz  /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_unpaired.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_unpaired.fastq.gz ILLUMINACLIP:adapters-primers.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:10 MINLEN:50</span></span>
<span id="cb26-71"><a href="#cb26-71"></a></span>
<span id="cb26-72"><a href="#cb26-72"></a><span class="in"># "$EBROOTTRIMMOMATIC/trimmomatic-0.39.jar" note that this is specific to the HPRC system we are using</span></span>
<span id="cb26-73"><a href="#cb26-73"></a></span>
<span id="cb26-74"><a href="#cb26-74"></a><span class="in">echo "Trimmomtatic complete. Repeating fastqc"</span></span>
<span id="cb26-75"><a href="#cb26-75"></a></span>
<span id="cb26-76"><a href="#cb26-76"></a><span class="in">module load FastQC/0.11.9-Java-11</span></span>
<span id="cb26-77"><a href="#cb26-77"></a></span>
<span id="cb26-78"><a href="#cb26-78"></a><span class="in">fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz</span></span>
<span id="cb26-79"><a href="#cb26-79"></a><span class="in">fastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz</span></span>
<span id="cb26-80"><a href="#cb26-80"></a><span class="in">```</span></span>
<span id="cb26-81"><a href="#cb26-81"></a></span>
<span id="cb26-82"><a href="#cb26-82"></a><span class="at">&gt; The above trimming steps took 615 MB of memory and 2 hours.</span></span>
<span id="cb26-83"><a href="#cb26-83"></a></span>
<span id="cb26-84"><a href="#cb26-84"></a><span class="fu">## 3. Remove ribosomal RNA</span></span>
<span id="cb26-85"><a href="#cb26-85"></a></span>
<span id="cb26-86"><a href="#cb26-86"></a><span class="co">[</span><span class="ot">Sortmerna</span><span class="co">](https://sortmerna.readthedocs.io/en/latest/installation.html)</span> installation guidelines and usage can be found here.</span>
<span id="cb26-87"><a href="#cb26-87"></a></span>
<span id="cb26-88"><a href="#cb26-88"></a>On the TAMU HPRC, this is where we needed to make a conda environment to run this.</span>
<span id="cb26-89"><a href="#cb26-89"></a></span>
<span id="cb26-90"><a href="#cb26-90"></a><span class="in">```</span></span>
<span id="cb26-91"><a href="#cb26-91"></a><span class="in"># Load anaconda</span></span>
<span id="cb26-92"><a href="#cb26-92"></a><span class="in">module load Anaconda3/2022.05</span></span>
<span id="cb26-93"><a href="#cb26-93"></a></span>
<span id="cb26-94"><a href="#cb26-94"></a><span class="in"># modify bioconda config for sortmeRNA</span></span>
<span id="cb26-95"><a href="#cb26-95"></a><span class="in">conda config --add channels defaults</span></span>
<span id="cb26-96"><a href="#cb26-96"></a><span class="in">conda config --add channels bioconda</span></span>
<span id="cb26-97"><a href="#cb26-97"></a><span class="in">conda config --add channels conda-forge</span></span>
<span id="cb26-98"><a href="#cb26-98"></a><span class="in">conda config --set channel_priority strict</span></span>
<span id="cb26-99"><a href="#cb26-99"></a><span class="in">```</span></span>
<span id="cb26-100"><a href="#cb26-100"></a></span>
<span id="cb26-101"><a href="#cb26-101"></a>Search for sortmerna using conda:</span>
<span id="cb26-102"><a href="#cb26-102"></a></span>
<span id="cb26-103"><a href="#cb26-103"></a><span class="in">```</span></span>
<span id="cb26-104"><a href="#cb26-104"></a><span class="in">conda search sortmerna</span></span>
<span id="cb26-105"><a href="#cb26-105"></a><span class="in">```</span></span>
<span id="cb26-106"><a href="#cb26-106"></a></span>
<span id="cb26-107"><a href="#cb26-107"></a>Create a conda environment specific for sortmerna, activate it, and install it.</span>
<span id="cb26-108"><a href="#cb26-108"></a></span>
<span id="cb26-109"><a href="#cb26-109"></a><span class="in">```</span></span>
<span id="cb26-110"><a href="#cb26-110"></a><span class="in">conda create --name sortmerna_env</span></span>
<span id="cb26-111"><a href="#cb26-111"></a><span class="in">conda activate sortmerna_env</span></span>
<span id="cb26-112"><a href="#cb26-112"></a><span class="in">conda install sortmerna</span></span>
<span id="cb26-113"><a href="#cb26-113"></a><span class="in">```</span></span>
<span id="cb26-114"><a href="#cb26-114"></a></span>
<span id="cb26-115"><a href="#cb26-115"></a>Answer "yes" (*Y*) to installation questions. Now when you run SortMeRNA, you need to activate this conda environment and execute your code. The next step is to download the databases to use for this program.</span>
<span id="cb26-116"><a href="#cb26-116"></a></span>
<span id="cb26-117"><a href="#cb26-117"></a><span class="fu">#### SortMeRNA databases</span></span>
<span id="cb26-118"><a href="#cb26-118"></a></span>
<span id="cb26-119"><a href="#cb26-119"></a>Separately, you need to download the databases to "align" and check the sequences for ribosomal RNAs. See <span class="in">`sortmerna-db-build.slurm`</span>.</span>
<span id="cb26-120"><a href="#cb26-120"></a></span>
<span id="cb26-121"><a href="#cb26-121"></a>Instructions for <span class="co">[</span><span class="ot">downloading version 4</span><span class="co">](https://sortmerna.readthedocs.io/en/latest/databases.html)</span>:</span>
<span id="cb26-122"><a href="#cb26-122"></a></span>
<span id="cb26-123"><a href="#cb26-123"></a><span class="in">```</span></span>
<span id="cb26-124"><a href="#cb26-124"></a><span class="in"># Move to the location you want your rRNA databases stored</span></span>
<span id="cb26-125"><a href="#cb26-125"></a><span class="in">cd /scratch/group/hu-lab/meta-eukomics/ </span></span>
<span id="cb26-126"><a href="#cb26-126"></a></span>
<span id="cb26-127"><a href="#cb26-127"></a><span class="in"># Download from github release </span></span>
<span id="cb26-128"><a href="#cb26-128"></a><span class="in">wget https://github.com/biocore/sortmerna/releases/download/v4.3.4/database.tar.gz</span></span>
<span id="cb26-129"><a href="#cb26-129"></a></span>
<span id="cb26-130"><a href="#cb26-130"></a><span class="in"># Make new directory for this and un-zip downloaded file</span></span>
<span id="cb26-131"><a href="#cb26-131"></a><span class="in">mkdir rRNA_databases_v4</span></span>
<span id="cb26-132"><a href="#cb26-132"></a><span class="in">tar -xvf database.tar.gz -C rRNA_databases_v4</span></span>
<span id="cb26-133"><a href="#cb26-133"></a><span class="in">```</span></span>
<span id="cb26-134"><a href="#cb26-134"></a></span>
<span id="cb26-135"><a href="#cb26-135"></a><span class="fu">### Run SortMeRNA (*optional*)</span></span>
<span id="cb26-136"><a href="#cb26-136"></a></span>
<span id="cb26-137"><a href="#cb26-137"></a>In your slurm script, activate conda, and then the sortmerna environment (<span class="in">`sortmeRNA.slurm`</span>):</span>
<span id="cb26-138"><a href="#cb26-138"></a></span>
<span id="cb26-139"><a href="#cb26-139"></a><span class="in">```</span></span>
<span id="cb26-140"><a href="#cb26-140"></a><span class="in"># Load anaconda</span></span>
<span id="cb26-141"><a href="#cb26-141"></a><span class="in">module load Anaconda3/2022.05</span></span>
<span id="cb26-142"><a href="#cb26-142"></a><span class="in">conda activate sortmerna_env</span></span>
<span id="cb26-143"><a href="#cb26-143"></a></span>
<span id="cb26-144"><a href="#cb26-144"></a><span class="in">mkdir /scratch/group/hu-lab/meta-eukomics/rRNA-sort</span></span>
<span id="cb26-145"><a href="#cb26-145"></a></span>
<span id="cb26-146"><a href="#cb26-146"></a><span class="in">sortmerna -ref /scratch/group/hu-lab/meta-eukomics/rRNA_databases_v4/smr_v4.3_sensitive_db.fasta \</span></span>
<span id="cb26-147"><a href="#cb26-147"></a><span class="in">-reads /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz \</span></span>
<span id="cb26-148"><a href="#cb26-148"></a><span class="in">-reads /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \</span></span>
<span id="cb26-149"><a href="#cb26-149"></a><span class="in">-workdir /scratch/group/hu-lab/meta-eukomics/rRNA-sort/ -aligned rRNA-aligned -other non-rRNA</span></span>
<span id="cb26-150"><a href="#cb26-150"></a><span class="in">-fastx --paired_in --out2 --threads $SLURM_CPUS_PER_TASK</span></span>
<span id="cb26-151"><a href="#cb26-151"></a><span class="in">```</span></span>
<span id="cb26-152"><a href="#cb26-152"></a></span>
<span id="cb26-153"><a href="#cb26-153"></a><span class="in">`-paired_in`</span>: The option 'paired_in' is optimal for users who want all reads in the other.fasta file to be non-rRNA. However, there are small chances that reads which are non-rRNA will also be put into the aligned.fasta file.</span>
<span id="cb26-154"><a href="#cb26-154"></a></span>
<span id="cb26-155"><a href="#cb26-155"></a>Since the SortmeRNA tool is optimized to take things that are aligned with the rRNA databases and put them in a file called "aligned", then we need to use the <span class="in">`other.fasta`</span> output file. The argument for this is <span class="in">`-out2`</span></span>
<span id="cb26-156"><a href="#cb26-156"></a></span>
<span id="cb26-157"><a href="#cb26-157"></a>Necessary flags for retaining the non-rRNA aligned reads and outputting them as separate R1 and R2 files: <span class="in">`-other`</span>, <span class="in">`-fastx`</span>, <span class="in">`--paired_in`</span>, and <span class="in">`--out2`</span>. To learn more about this check out this thread: *How do I properly run sortmerna?* https://github.com/sortmerna/sortmerna/issues/333</span>
<span id="cb26-158"><a href="#cb26-158"></a></span>
<span id="cb26-159"><a href="#cb26-159"></a><span class="at">&gt; This was run with 32 threads and 1 node. It took 2 hours 45 minutes and used just over 16 GB of memory.</span></span>
<span id="cb26-160"><a href="#cb26-160"></a></span>
<span id="cb26-161"><a href="#cb26-161"></a><span class="at">&gt; The total number of reads that aligned to the rRNA databases was pretty small. I am planning to not use the Sorted reads, as there are some issue with the program. Will look for another way to sort reads.</span></span>
<span id="cb26-162"><a href="#cb26-162"></a></span>
<span id="cb26-163"><a href="#cb26-163"></a><span class="fu">## 4. Assembly</span></span>
<span id="cb26-164"><a href="#cb26-164"></a></span>
<span id="cb26-165"><a href="#cb26-165"></a>The next step is to take all the trimmed reads and bring them together to make longer, more continuous sequences, called *contigs*. Here, we will use two assemblers and combine the results. Each one is built slightly differently.</span>
<span id="cb26-166"><a href="#cb26-166"></a></span>
<span id="cb26-167"><a href="#cb26-167"></a><span class="fu">### MEGAHIT (assembly 1)</span></span>
<span id="cb26-168"><a href="#cb26-168"></a></span>
<span id="cb26-169"><a href="#cb26-169"></a>We will first use <span class="co">[</span><span class="ot">megahit</span><span class="co">](https://github.com/voutcn/megahit)</span>. To save the assemblies separately, make a new assembly output file in your working <span class="in">`scratch`</span> space. <span class="in">`mkdir /scratch/group/hu-lab/meta-eukomics/assembly`</span></span>
<span id="cb26-170"><a href="#cb26-170"></a></span>
<span id="cb26-171"><a href="#cb26-171"></a>The megahit command below, outputs contigs in the new <span class="in">`assembly`</span> directory, only keeps reads longer than 100 bps, and uses the megahit preset for lots of diversity in a sample (*meta-large*).</span>
<span id="cb26-172"><a href="#cb26-172"></a></span>
<span id="cb26-173"><a href="#cb26-173"></a>Megahit uses multiple k-mer strategy, and we can set the min and max k. In order to reduce the complexity of the *de Bruijin* graph, a kmin size of 25 and higher (like 27) is better.</span>
<span id="cb26-174"><a href="#cb26-174"></a></span>
<span id="cb26-175"><a href="#cb26-175"></a>See slurm script: <span class="in">`megahit-assembly.slurm`</span></span>
<span id="cb26-176"><a href="#cb26-176"></a></span>
<span id="cb26-177"><a href="#cb26-177"></a><span class="in">```</span></span>
<span id="cb26-178"><a href="#cb26-178"></a><span class="in">module load GCCcore/11.2.0</span></span>
<span id="cb26-179"><a href="#cb26-179"></a><span class="in">module load MEGAHIT/1.2.9</span></span>
<span id="cb26-180"><a href="#cb26-180"></a></span>
<span id="cb26-181"><a href="#cb26-181"></a><span class="in">megahit -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz -o /scratch/group/hu-lab/meta-eukomics/assembly/ --min-contig-len 1000 --presets meta-large --num-cpu-threads 32</span></span>
<span id="cb26-182"><a href="#cb26-182"></a><span class="in">```</span></span>
<span id="cb26-183"><a href="#cb26-183"></a></span>
<span id="cb26-184"><a href="#cb26-184"></a><span class="at">&gt; With the above settings, megahit recovered 31,331 contigs, total 44610184 bp, min 1000 bp, max 10674 bp, avg 1423 bp, N50 1391 bp. And this took about *10 hours*.</span></span>
<span id="cb26-185"><a href="#cb26-185"></a></span>
<span id="cb26-186"><a href="#cb26-186"></a><span class="at">&gt; On the HPC, this was run on 1 node, 4 cores per node, and it used 18.5 GBs of memory.</span></span>
<span id="cb26-187"><a href="#cb26-187"></a></span>
<span id="cb26-188"><a href="#cb26-188"></a>Megahit assembly location: <span class="in">`/scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa`</span></span>
<span id="cb26-189"><a href="#cb26-189"></a></span>
<span id="cb26-190"><a href="#cb26-190"></a>*Optional*: Visualize your megahit assembly</span>
<span id="cb26-191"><a href="#cb26-191"></a></span>
<span id="cb26-192"><a href="#cb26-192"></a>When megahit assembly is complete, use this option to visualize it: https://github.com/voutcn/megahit/wiki/Visualizing-MEGAHIT's-contig-graph</span>
<span id="cb26-193"><a href="#cb26-193"></a></span>
<span id="cb26-194"><a href="#cb26-194"></a><span class="fu">### IDBA-Tran (assembly 2)</span></span>
<span id="cb26-195"><a href="#cb26-195"></a></span>
<span id="cb26-196"><a href="#cb26-196"></a><span class="co">[</span><span class="ot">IDBA-tran</span><span class="co">](https://i.cs.hku.hk/~alse/hkubrg/projects/idba_tran/index.html)</span> is another *de novo* assembler. Uses local assembly to reconstruct missing kmers in low-expressed transcripts.</span>
<span id="cb26-197"><a href="#cb26-197"></a></span>
<span id="cb26-198"><a href="#cb26-198"></a>See script: <span class="in">`idba-assembly.slurm`</span> to run assembly with minimum kmer at 20 and max kmer at 50 with a 5 step increment of kmer.</span>
<span id="cb26-199"><a href="#cb26-199"></a></span>
<span id="cb26-200"><a href="#cb26-200"></a><span class="in">```</span></span>
<span id="cb26-201"><a href="#cb26-201"></a><span class="in">echo "unzip files"</span></span>
<span id="cb26-202"><a href="#cb26-202"></a><span class="in">gunzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R*_trimmed.fastq.gz</span></span>
<span id="cb26-203"><a href="#cb26-203"></a></span>
<span id="cb26-204"><a href="#cb26-204"></a><span class="in">module load GCC/8.2.0-2.31.1 </span></span>
<span id="cb26-205"><a href="#cb26-205"></a><span class="in">module load IDBA-UD/1.1.3</span></span>
<span id="cb26-206"><a href="#cb26-206"></a></span>
<span id="cb26-207"><a href="#cb26-207"></a><span class="in"># Convert fastq R1 and R2 files into a single 'interleaved` fastq files</span></span>
<span id="cb26-208"><a href="#cb26-208"></a><span class="in">fq2fa --merge --filter /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq /scratch/group/hu-lab/meta-eukomics/assembly/merged-PE-for-idba.fa</span></span>
<span id="cb26-209"><a href="#cb26-209"></a></span>
<span id="cb26-210"><a href="#cb26-210"></a><span class="in"># Run assembly</span></span>
<span id="cb26-211"><a href="#cb26-211"></a><span class="in">idba_tran -r /scratch/group/hu-lab/meta-eukomics/assembly/merged-PE-for-idba.fa -o /scratch/group/hu-lab/meta-eukomics/assembly/idba-out --mink 20 --maxk 50 --step 5 --num_threads 16</span></span>
<span id="cb26-212"><a href="#cb26-212"></a></span>
<span id="cb26-213"><a href="#cb26-213"></a><span class="in"># Make sure fastq files are re-zipped:</span></span>
<span id="cb26-214"><a href="#cb26-214"></a><span class="in">gzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq</span></span>
<span id="cb26-215"><a href="#cb26-215"></a><span class="in">gzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq</span></span>
<span id="cb26-216"><a href="#cb26-216"></a><span class="in">```</span></span>
<span id="cb26-217"><a href="#cb26-217"></a></span>
<span id="cb26-218"><a href="#cb26-218"></a><span class="at">&gt; Using 8 cores, the IDBA-tran assembly took about 23 hours and used 130 GB of memory.</span></span>
<span id="cb26-219"><a href="#cb26-219"></a></span>
<span id="cb26-220"><a href="#cb26-220"></a>The *IDBA-tran output* includes separation by k-mer length. So there are multiple "contig-X.fa" files. Where <span class="in">`contig-25.fa`</span> is the output contigs at k-mer = 25. The IDBA program determines which one is best and then puts this into the final <span class="in">`contig.fa`</span> file. Output: <span class="in">`/scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa`</span></span>
<span id="cb26-221"><a href="#cb26-221"></a></span>
<span id="cb26-222"><a href="#cb26-222"></a><span class="fu">## 5. Evaluate assemblies</span></span>
<span id="cb26-223"><a href="#cb26-223"></a></span>
<span id="cb26-224"><a href="#cb26-224"></a><span class="fu">### QUAST</span></span>
<span id="cb26-225"><a href="#cb26-225"></a></span>
<span id="cb26-226"><a href="#cb26-226"></a>QUAST stands for *QUality ASsessment Tool* and it is a tool for evaluating assemblies. Not all tools for evaluating assemblies will work, as most are built for metagenomics or require a reference genome. In this case, we do not have a reference genome.</span>
<span id="cb26-227"><a href="#cb26-227"></a></span>
<span id="cb26-228"><a href="#cb26-228"></a>*First for the IDBA output* <span class="in">`quast-idba.slurm`</span>:</span>
<span id="cb26-229"><a href="#cb26-229"></a></span>
<span id="cb26-230"><a href="#cb26-230"></a><span class="in">```</span></span>
<span id="cb26-231"><a href="#cb26-231"></a><span class="in">module load GCC/9.3.0</span></span>
<span id="cb26-232"><a href="#cb26-232"></a><span class="in">module load OpenMPI/4.0.3</span></span>
<span id="cb26-233"><a href="#cb26-233"></a><span class="in">module load QUAST/5.0.2-Python-3.8.2</span></span>
<span id="cb26-234"><a href="#cb26-234"></a></span>
<span id="cb26-235"><a href="#cb26-235"></a><span class="in">quast.py /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa \</span></span>
<span id="cb26-236"><a href="#cb26-236"></a><span class="in">        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \</span></span>
<span id="cb26-237"><a href="#cb26-237"></a><span class="in">        -o /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/ \</span></span>
<span id="cb26-238"><a href="#cb26-238"></a><span class="in">        --threads $SLURM_CPUS_PER_TASK</span></span>
<span id="cb26-239"><a href="#cb26-239"></a><span class="in">```</span></span>
<span id="cb26-240"><a href="#cb26-240"></a></span>
<span id="cb26-241"><a href="#cb26-241"></a><span class="at">&gt; This was run on 1 node with 16 cores. It used 3.5 GB of memory in about 1 hour. 6:15 CPUs used.</span></span>
<span id="cb26-242"><a href="#cb26-242"></a></span>
<span id="cb26-243"><a href="#cb26-243"></a>*Repeat for the megahit output* <span class="in">`quast-megahit.slurm`</span>:</span>
<span id="cb26-244"><a href="#cb26-244"></a></span>
<span id="cb26-245"><a href="#cb26-245"></a><span class="in">```</span></span>
<span id="cb26-246"><a href="#cb26-246"></a><span class="in">module load GCC/9.3.0</span></span>
<span id="cb26-247"><a href="#cb26-247"></a><span class="in">module load OpenMPI/4.0.3</span></span>
<span id="cb26-248"><a href="#cb26-248"></a><span class="in">module load QUAST/5.0.2-Python-3.8.2</span></span>
<span id="cb26-249"><a href="#cb26-249"></a></span>
<span id="cb26-250"><a href="#cb26-250"></a><span class="in">quast.py /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa \</span></span>
<span id="cb26-251"><a href="#cb26-251"></a><span class="in">        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \</span></span>
<span id="cb26-252"><a href="#cb26-252"></a><span class="in">        -o /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/ \</span></span>
<span id="cb26-253"><a href="#cb26-253"></a><span class="in">        --threads $SLURM_CPUS_PER_TASK</span></span>
<span id="cb26-254"><a href="#cb26-254"></a><span class="in">```</span></span>
<span id="cb26-255"><a href="#cb26-255"></a></span>
<span id="cb26-256"><a href="#cb26-256"></a><span class="at">&gt; At 16 cores (1 node), this took about 1 hour at 3 GB of memory.</span></span>
<span id="cb26-257"><a href="#cb26-257"></a></span>
<span id="cb26-258"><a href="#cb26-258"></a><span class="fu">#### Interpret QUAST</span></span>
<span id="cb26-259"><a href="#cb26-259"></a></span>
<span id="cb26-260"><a href="#cb26-260"></a>Download files locally from:</span>
<span id="cb26-261"><a href="#cb26-261"></a></span>
<span id="cb26-262"><a href="#cb26-262"></a><span class="ss">-   </span>PDF files: <span class="in">`meta-eukomics/assembly/*-out/basic_stats/*.pdf`</span></span>
<span id="cb26-263"><a href="#cb26-263"></a><span class="ss">-   </span>Use an ICARUS html viewer: <span class="in">`meta-eukomics/assembly/*-out/icarus*`</span></span>
<span id="cb26-264"><a href="#cb26-264"></a><span class="ss">-   </span>Basic read stats: <span class="in">`meta-eukomics/assembly/*-out/reads_stats/reads_report.tsv`</span></span>
<span id="cb26-265"><a href="#cb26-265"></a></span>
<span id="cb26-266"><a href="#cb26-266"></a><span class="fu">##### Example output from QUAST</span></span>
<span id="cb26-267"><a href="#cb26-267"></a></span>
<span id="cb26-268"><a href="#cb26-268"></a>*idba output*</span>
<span id="cb26-269"><a href="#cb26-269"></a></span>
<span id="cb26-270"><a href="#cb26-270"></a><span class="in">```         </span></span>
<span id="cb26-271"><a href="#cb26-271"></a><span class="in">Assembly                    contig   </span></span>
<span id="cb26-272"><a href="#cb26-272"></a><span class="in"># contigs (&gt;= 0 bp)         892652   </span></span>
<span id="cb26-273"><a href="#cb26-273"></a><span class="in"># contigs (&gt;= 1000 bp)      13948    </span></span>
<span id="cb26-274"><a href="#cb26-274"></a><span class="in"># contigs (&gt;= 5000 bp)      16       </span></span>
<span id="cb26-275"><a href="#cb26-275"></a><span class="in"># contigs (&gt;= 10000 bp)     0        </span></span>
<span id="cb26-276"><a href="#cb26-276"></a><span class="in"># contigs (&gt;= 25000 bp)     0        </span></span>
<span id="cb26-277"><a href="#cb26-277"></a><span class="in"># contigs (&gt;= 50000 bp)     0        </span></span>
<span id="cb26-278"><a href="#cb26-278"></a><span class="in">Total length (&gt;= 0 bp)      310591507</span></span>
<span id="cb26-279"><a href="#cb26-279"></a><span class="in">Total length (&gt;= 1000 bp)   19165345 </span></span>
<span id="cb26-280"><a href="#cb26-280"></a><span class="in">Total length (&gt;= 5000 bp)   101378   </span></span>
<span id="cb26-281"><a href="#cb26-281"></a><span class="in">Total length (&gt;= 10000 bp)  0        </span></span>
<span id="cb26-282"><a href="#cb26-282"></a><span class="in">Total length (&gt;= 25000 bp)  0        </span></span>
<span id="cb26-283"><a href="#cb26-283"></a><span class="in">Total length (&gt;= 50000 bp)  0        </span></span>
<span id="cb26-284"><a href="#cb26-284"></a><span class="in"># contigs                   105801   </span></span>
<span id="cb26-285"><a href="#cb26-285"></a><span class="in">Largest contig              9483     </span></span>
<span id="cb26-286"><a href="#cb26-286"></a><span class="in">Total length                78684450 </span></span>
<span id="cb26-287"><a href="#cb26-287"></a><span class="in">GC (%)                      53.19    </span></span>
<span id="cb26-288"><a href="#cb26-288"></a><span class="in">N50                         714      </span></span>
<span id="cb26-289"><a href="#cb26-289"></a><span class="in">N75                         581      </span></span>
<span id="cb26-290"><a href="#cb26-290"></a><span class="in">L50                         38334    </span></span>
<span id="cb26-291"><a href="#cb26-291"></a><span class="in">L75                         69112    </span></span>
<span id="cb26-292"><a href="#cb26-292"></a><span class="in"># total reads               110011298</span></span>
<span id="cb26-293"><a href="#cb26-293"></a><span class="in"># left                      54322593 </span></span>
<span id="cb26-294"><a href="#cb26-294"></a><span class="in"># right                     54322593 </span></span>
<span id="cb26-295"><a href="#cb26-295"></a><span class="in">Mapped (%)                  28.29    </span></span>
<span id="cb26-296"><a href="#cb26-296"></a><span class="in">Properly paired (%)         19.43    </span></span>
<span id="cb26-297"><a href="#cb26-297"></a><span class="in">Avg. coverage depth         27       </span></span>
<span id="cb26-298"><a href="#cb26-298"></a><span class="in">Coverage &gt;= 1x (%)          99.98    </span></span>
<span id="cb26-299"><a href="#cb26-299"></a><span class="in"># N's per 100 kbp           0.00     </span></span>
<span id="cb26-300"><a href="#cb26-300"></a><span class="in">```</span></span>
<span id="cb26-301"><a href="#cb26-301"></a></span>
<span id="cb26-302"><a href="#cb26-302"></a>*megahit output*</span>
<span id="cb26-303"><a href="#cb26-303"></a></span>
<span id="cb26-304"><a href="#cb26-304"></a><span class="in">```         </span></span>
<span id="cb26-305"><a href="#cb26-305"></a><span class="in">Assembly                    final.contigs</span></span>
<span id="cb26-306"><a href="#cb26-306"></a><span class="in"># contigs (&gt;= 0 bp)         31331        </span></span>
<span id="cb26-307"><a href="#cb26-307"></a><span class="in"># contigs (&gt;= 1000 bp)      31331        </span></span>
<span id="cb26-308"><a href="#cb26-308"></a><span class="in"># contigs (&gt;= 5000 bp)      27           </span></span>
<span id="cb26-309"><a href="#cb26-309"></a><span class="in"># contigs (&gt;= 10000 bp)     2            </span></span>
<span id="cb26-310"><a href="#cb26-310"></a><span class="in"># contigs (&gt;= 25000 bp)     0            </span></span>
<span id="cb26-311"><a href="#cb26-311"></a><span class="in"># contigs (&gt;= 50000 bp)     0            </span></span>
<span id="cb26-312"><a href="#cb26-312"></a><span class="in">Total length (&gt;= 0 bp)      44610184     </span></span>
<span id="cb26-313"><a href="#cb26-313"></a><span class="in">Total length (&gt;= 1000 bp)   44610184     </span></span>
<span id="cb26-314"><a href="#cb26-314"></a><span class="in">Total length (&gt;= 5000 bp)   176055       </span></span>
<span id="cb26-315"><a href="#cb26-315"></a><span class="in">Total length (&gt;= 10000 bp)  21295        </span></span>
<span id="cb26-316"><a href="#cb26-316"></a><span class="in">Total length (&gt;= 25000 bp)  0            </span></span>
<span id="cb26-317"><a href="#cb26-317"></a><span class="in">Total length (&gt;= 50000 bp)  0            </span></span>
<span id="cb26-318"><a href="#cb26-318"></a><span class="in"># contigs                   31331        </span></span>
<span id="cb26-319"><a href="#cb26-319"></a><span class="in">Largest contig              10674        </span></span>
<span id="cb26-320"><a href="#cb26-320"></a><span class="in">Total length                44610184     </span></span>
<span id="cb26-321"><a href="#cb26-321"></a><span class="in">GC (%)                      53.78        </span></span>
<span id="cb26-322"><a href="#cb26-322"></a><span class="in">N50                         1391         </span></span>
<span id="cb26-323"><a href="#cb26-323"></a><span class="in">N75                         1152         </span></span>
<span id="cb26-324"><a href="#cb26-324"></a><span class="in">L50                         12043        </span></span>
<span id="cb26-325"><a href="#cb26-325"></a><span class="in">L75                         20904        </span></span>
<span id="cb26-326"><a href="#cb26-326"></a><span class="in"># total reads               108929544    </span></span>
<span id="cb26-327"><a href="#cb26-327"></a><span class="in"># left                      54322593     </span></span>
<span id="cb26-328"><a href="#cb26-328"></a><span class="in"># right                     54322593     </span></span>
<span id="cb26-329"><a href="#cb26-329"></a><span class="in">Mapped (%)                  24.47        </span></span>
<span id="cb26-330"><a href="#cb26-330"></a><span class="in">Properly paired (%)         18.5         </span></span>
<span id="cb26-331"><a href="#cb26-331"></a><span class="in">Avg. coverage depth         47           </span></span>
<span id="cb26-332"><a href="#cb26-332"></a><span class="in">Coverage &gt;= 1x (%)          99.98        </span></span>
<span id="cb26-333"><a href="#cb26-333"></a><span class="in"># N's per 100 kbp           0.00         </span></span>
<span id="cb26-334"><a href="#cb26-334"></a><span class="in">```</span></span>
<span id="cb26-335"><a href="#cb26-335"></a></span>
<span id="cb26-336"><a href="#cb26-336"></a>Notes on comparison:</span>
<span id="cb26-337"><a href="#cb26-337"></a></span>
<span id="cb26-338"><a href="#cb26-338"></a>IDBA output a lot more contigs, but they are shorter. Megahit has many fewer (31,331 / 105,801) of the total contigs. However, contigs over 1000 bps from IDBA drops to only 13K. Demonstrating that most of them are between 500 - 1000 bps (because the program only reports contigs greater than 500 bps). Megahit, on the otherhand, has over 31k contigs that are greater than 1000 bps in length. For super long contigs, we get 27 from megahit and only 16 from idba (<span class="sc">\&gt;</span>5K bps).</span>
<span id="cb26-339"><a href="#cb26-339"></a></span>
<span id="cb26-340"><a href="#cb26-340"></a>As a result, we do get more of the original transcripts mapping to the IDBA output. but the average coverage is 27. Megahit has a few points fewer for % mapped, but the average coverage depth is 47.</span>
<span id="cb26-341"><a href="#cb26-341"></a></span>
<span id="cb26-342"><a href="#cb26-342"></a>These assemblies can be combined below.</span>
<span id="cb26-343"><a href="#cb26-343"></a></span>
<span id="cb26-344"><a href="#cb26-344"></a><span class="fu">## 6. Cluster assembly output (mmseqs2)</span></span>
<span id="cb26-345"><a href="#cb26-345"></a></span>
<span id="cb26-346"><a href="#cb26-346"></a>Because we have outputs from two separate assemblies, we can use a program to "cluster" the output contigs together. The clustering / merging of contigs is based on sequence similarity, so we need to include a similarity parameter that is kind of arbitrary.</span>
<span id="cb26-347"><a href="#cb26-347"></a></span>
<span id="cb26-348"><a href="#cb26-348"></a>We will use <span class="co">[</span><span class="ot">mmseqs2</span><span class="co">](https://github.com/soedinglab/MMseqs2)</span> and try this at 99% similarity. MMseq stands for "Many-against-Many sequence searching"</span>
<span id="cb26-349"><a href="#cb26-349"></a></span>
<span id="cb26-350"><a href="#cb26-350"></a>First, the output contig files from IDBA and Megahit are combined: <span class="in">`cluster-mmseqs2.slurm`</span></span>
<span id="cb26-351"><a href="#cb26-351"></a></span>
<span id="cb26-352"><a href="#cb26-352"></a><span class="in">```</span></span>
<span id="cb26-353"><a href="#cb26-353"></a><span class="in"># Precursor load to use MMseqs2 on HPRC</span></span>
<span id="cb26-354"><a href="#cb26-354"></a><span class="in">module load GCC/10.2.0</span></span>
<span id="cb26-355"><a href="#cb26-355"></a><span class="in">module load OpenMPI/4.0.5</span></span>
<span id="cb26-356"><a href="#cb26-356"></a><span class="in">module load MMseqs2/13-45111</span></span>
<span id="cb26-357"><a href="#cb26-357"></a></span>
<span id="cb26-358"><a href="#cb26-358"></a><span class="in">mkdir /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly</span></span>
<span id="cb26-359"><a href="#cb26-359"></a></span>
<span id="cb26-360"><a href="#cb26-360"></a><span class="in">cat /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa &gt; /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta</span></span>
<span id="cb26-361"><a href="#cb26-361"></a></span>
<span id="cb26-362"><a href="#cb26-362"></a></span>
<span id="cb26-363"><a href="#cb26-363"></a><span class="in"># Use the 'easy-linclust' option</span></span>
<span id="cb26-364"><a href="#cb26-364"></a></span>
<span id="cb26-365"><a href="#cb26-365"></a><span class="in">mmseqs easy-linclust /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/clusterRes /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/tmp --threads=$SLURM_CPUS_PER_TASK</span></span>
<span id="cb26-366"><a href="#cb26-366"></a></span>
<span id="cb26-367"><a href="#cb26-367"></a><span class="in">```</span></span>
<span id="cb26-368"><a href="#cb26-368"></a></span>
<span id="cb26-369"><a href="#cb26-369"></a>If you're working with a massive amount of data, this is a good place to try reducing the percent identity with mmseqs down to 99% or 98%.</span>
<span id="cb26-370"><a href="#cb26-370"></a></span>
<span id="cb26-371"><a href="#cb26-371"></a><span class="at">&gt; 32 cores (1 node), this took just under 1 hour and 1.3 GB of memory.</span></span>
<span id="cb26-372"><a href="#cb26-372"></a></span>
<span id="cb26-373"><a href="#cb26-373"></a><span class="fu">### 6.1 QUAST new combined assembly</span></span>
<span id="cb26-374"><a href="#cb26-374"></a></span>
<span id="cb26-375"><a href="#cb26-375"></a>Repeat assembly evaluation with quast (<span class="in">`quast-combined.slurm`</span>)</span>
<span id="cb26-376"><a href="#cb26-376"></a></span>
<span id="cb26-377"><a href="#cb26-377"></a><span class="in">```</span></span>
<span id="cb26-378"><a href="#cb26-378"></a><span class="in">quast.py /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta \</span></span>
<span id="cb26-379"><a href="#cb26-379"></a><span class="in">        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \</span></span>
<span id="cb26-380"><a href="#cb26-380"></a><span class="in">        -o /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/ \</span></span>
<span id="cb26-381"><a href="#cb26-381"></a><span class="in">        --threads $SLURM_CPUS_PER_TASK</span></span>
<span id="cb26-382"><a href="#cb26-382"></a><span class="in">```</span></span>
<span id="cb26-383"><a href="#cb26-383"></a></span>
<span id="cb26-384"><a href="#cb26-384"></a>Now, with a combined assembly we get a better deal with our contigs. We have more like 137,132 contigs. This is more than both IDBA and megahit, but we are now getting more than 45K greater than 1000 bp, and 43 greater than 5K bps. And now, the percent mapped from original reads is higher at 31%, but our average coverage depth drops to 21. This is fine because we can map more reads to our assemblies.</span>
<span id="cb26-385"><a href="#cb26-385"></a></span>
<span id="cb26-386"><a href="#cb26-386"></a><span class="fu">## 7. Transdecoder</span></span>
<span id="cb26-387"><a href="#cb26-387"></a></span>
<span id="cb26-388"><a href="#cb26-388"></a>From the combined assemblies, we need to extract the long open reading frames (ORFs). ORFs will be identified that have at least 100 aminos acids. Then we also follow this with predicting the likely coding regions so we can continue with protein annotation.</span>
<span id="cb26-389"><a href="#cb26-389"></a></span>
<span id="cb26-390"><a href="#cb26-390"></a><span class="in">`transdecoder.slurm`</span>:</span>
<span id="cb26-391"><a href="#cb26-391"></a></span>
<span id="cb26-392"><a href="#cb26-392"></a><span class="in">```</span></span>
<span id="cb26-393"><a href="#cb26-393"></a><span class="in">module load GCC/11.3.0</span></span>
<span id="cb26-394"><a href="#cb26-394"></a><span class="in">module load TransDecoder/5.5.0</span></span>
<span id="cb26-395"><a href="#cb26-395"></a></span>
<span id="cb26-396"><a href="#cb26-396"></a><span class="in">#extract the long open reading frames</span></span>
<span id="cb26-397"><a href="#cb26-397"></a><span class="in">TransDecoder.LongOrfs -t /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta --output_dir /scratch/group/hu-lab/meta-eukomics/predictions/</span></span>
<span id="cb26-398"><a href="#cb26-398"></a></span>
<span id="cb26-399"><a href="#cb26-399"></a><span class="in"># predict the likely coding regions</span></span>
<span id="cb26-400"><a href="#cb26-400"></a><span class="in">TransDecoder.Predict -t /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta --output_dir /scratch/group/hu-lab/meta-eukomics/predictions/</span></span>
<span id="cb26-401"><a href="#cb26-401"></a><span class="in">```</span></span>
<span id="cb26-402"><a href="#cb26-402"></a></span>
<span id="cb26-403"><a href="#cb26-403"></a>Output files: <span class="in">`/scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta.transdecoder.*`</span></span>
<span id="cb26-404"><a href="#cb26-404"></a></span>
<span id="cb26-405"><a href="#cb26-405"></a><span class="at">&gt; At 16 cores (1 node), job took 5.5 GB of memory and 1 hour.</span></span>
<span id="cb26-406"><a href="#cb26-406"></a></span>
<span id="cb26-407"><a href="#cb26-407"></a><span class="fu">### 7.1 (optional) MMSeq2 part II</span></span>
<span id="cb26-408"><a href="#cb26-408"></a></span>
<span id="cb26-409"><a href="#cb26-409"></a>At this point, if you have a LOT of samples and large amounts of data, a repeat clustering of the proteins will help reduce the amount of data you're working with.</span>
<span id="cb26-410"><a href="#cb26-410"></a></span>
<span id="cb26-411"><a href="#cb26-411"></a><span class="fu">## 8. Key output files</span></span>
<span id="cb26-412"><a href="#cb26-412"></a></span>
<span id="cb26-413"><a href="#cb26-413"></a>At this point, you have assembled, quality checked, and predicted proteins for all your metatranscriptomes.</span>
<span id="cb26-414"><a href="#cb26-414"></a></span>
<span id="cb26-415"><a href="#cb26-415"></a><span class="ss">-   </span>Assembled contigs: <span class="in">`/scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/clusterRes_rep_seq.fasta`</span></span>
<span id="cb26-416"><a href="#cb26-416"></a></span>
<span id="cb26-417"><a href="#cb26-417"></a><span class="ss">-   </span>Predicted proteins: <span class="in">`/scratch/group/hu-lab/meta-eukomics/predictions`</span> see files ending in .gff3 and .pep</span>
<span id="cb26-418"><a href="#cb26-418"></a></span>
<span id="cb26-419"><a href="#cb26-419"></a><span class="ss">-   </span><span class="in">`/scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta.transdecoder.*`</span></span>
<span id="cb26-420"><a href="#cb26-420"></a></span>
<span id="cb26-421"><a href="#cb26-421"></a>*Next steps*: annotate above files, based on predicted proteins or the contigs and determine transcript abundance by mapping the original trimmed fastq reads back onto these contigs.</span>
<span id="cb26-422"><a href="#cb26-422"></a></span>
<span id="cb26-423"><a href="#cb26-423"></a><span class="fu">## 9. Annotation</span></span>
<span id="cb26-424"><a href="#cb26-424"></a></span>
<span id="cb26-425"><a href="#cb26-425"></a>The goal of the below steps is to match assembled reads with taxonomy and protein databases.</span>
<span id="cb26-426"><a href="#cb26-426"></a></span>
<span id="cb26-427"><a href="#cb26-427"></a><span class="fu">### 9.1 Marferret &amp; Diamond</span></span>
<span id="cb26-428"><a href="#cb26-428"></a></span>
<span id="cb26-429"><a href="#cb26-429"></a>For taxonomic annotation, using <span class="co">[</span><span class="ot">MarFERReT</span><span class="co">](https://github.com/armbrustlab/marferret)</span></span>
<span id="cb26-430"><a href="#cb26-430"></a></span>
<span id="cb26-431"><a href="#cb26-431"></a>For this we will use <span class="co">[</span><span class="ot">Diamond</span><span class="co">](https://github.com/bbuchfink/diamond)</span>. This is a really fast tool for querying nucleotide or protein sequences again a database. You need to first make a diamond database (<span class="in">`.dmnd`</span>), and then use <span class="in">`blastp`</span> or something to</span>
<span id="cb26-432"><a href="#cb26-432"></a></span>
<span id="cb26-433"><a href="#cb26-433"></a>To use the Marferrt resource, we need to query our combined assembly and predicted protein IDs with the Marferret this with diamond.</span>
<span id="cb26-434"><a href="#cb26-434"></a></span>
<span id="cb26-435"><a href="#cb26-435"></a>In order to run Diamond (or any similar blast-like program), we need to consider a few variables &amp; terms.</span>
<span id="cb26-436"><a href="#cb26-436"></a></span>
<span id="cb26-437"><a href="#cb26-437"></a><span class="ss">-   </span>*e-value* (expectation value): This is the number of hits that could be found by chance. So an e-value of 50, means up to 50 of the matches (or hits) in your results could be a result of chance. Therefore, lower e-values mean you will get better matches, or matches of better quality. Generally, these programs may have e-value defaults of 10, which may be helpful for looking at all possible results. But an e-value of 0.01 would be better to use to look for good matches. There is a formula for how we calcuate e-values, and it depends on the size of the query sequences and the databases.</span>
<span id="cb26-438"><a href="#cb26-438"></a></span>
<span id="cb26-439"><a href="#cb26-439"></a><span class="ss">-   </span>*Bit score*: This is the result of a log2 scaled and normalized score of the number of matches that could be found by chance based on the database size.</span>
<span id="cb26-440"><a href="#cb26-440"></a></span>
<span id="cb26-441"><a href="#cb26-441"></a>Diamond default e-value is 0.001, I am changing mine to 0.0001. And I'm using the <span class="in">`--sensitive`</span> setting which finds significant matches with <span class="sc">\&gt;</span>50 bits for fragments that are between 30-40 aa.</span>
<span id="cb26-442"><a href="#cb26-442"></a></span>
<span id="cb26-443"><a href="#cb26-443"></a><span class="in">```</span></span>
<span id="cb26-444"><a href="#cb26-444"></a><span class="in">module load GCC/11.2.0</span></span>
<span id="cb26-445"><a href="#cb26-445"></a><span class="in">module load DIAMOND/2.0.15</span></span>
<span id="cb26-446"><a href="#cb26-446"></a></span>
<span id="cb26-447"><a href="#cb26-447"></a><span class="in">diamond blastp --threads $SLURM_CPUS_PER_TASK --query /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/combined-assemblies.fasta.transdecoder.pep --db /scratch/group/hu-lab/marferret/data/MarFERReT.v1.1.1.dmnd -o /scratch/group/hu-lab/meta-eukomics/annotation/meta-eukomic_marferret_07082024.txt --sensitive --evalue 0.0001 --max-target-seqs 10 --outfmt 6 qseqid sseqid sallseqid evalue bitscore qlen slen</span></span>
<span id="cb26-448"><a href="#cb26-448"></a><span class="in">```</span></span>
<span id="cb26-449"><a href="#cb26-449"></a></span>
<span id="cb26-450"><a href="#cb26-450"></a><span class="at">&gt; With 32 cores (1 node), this took 20 minutes and 10 GB of memory.</span></span>
<span id="cb26-451"><a href="#cb26-451"></a></span>
<span id="cb26-452"><a href="#cb26-452"></a><span class="fu">## 10. Transcript counts</span></span>
<span id="cb26-453"><a href="#cb26-453"></a></span>
<span id="cb26-454"><a href="#cb26-454"></a>For determining "gene expression", we estimate this from the number of transcripts (sequenced reads) that map onto your assembled reads. We will use <span class="co">[</span><span class="ot">salmon</span><span class="co">](https://combine-lab.github.io/salmon/#:~:text=Salmon%20is%20a%20tool%20for,and%20while%20using%20little%20memory.)</span>.</span>
<span id="cb26-455"><a href="#cb26-455"></a></span>
<span id="cb26-456"><a href="#cb26-456"></a>First we need to index your transcripts - salmon uses a quasi-map approach to quantify the reads.</span>
<span id="cb26-457"><a href="#cb26-457"></a></span>
<span id="cb26-458"><a href="#cb26-458"></a><span class="in">```</span></span>
<span id="cb26-459"><a href="#cb26-459"></a><span class="in">module load GCC/11.2.0</span></span>
<span id="cb26-460"><a href="#cb26-460"></a><span class="in">module load OpenMPI/4.1.1</span></span>
<span id="cb26-461"><a href="#cb26-461"></a><span class="in">module load Salmon/1.7.0</span></span>
<span id="cb26-462"><a href="#cb26-462"></a></span>
<span id="cb26-463"><a href="#cb26-463"></a><span class="in">mkdir /scratch/group/hu-lab/meta-eukomics/salmon-quant</span></span>
<span id="cb26-464"><a href="#cb26-464"></a></span>
<span id="cb26-465"><a href="#cb26-465"></a><span class="in">salmon index -t /scratch/group/hu-lab/meta-eukomics/assembly/combined-assembly/clusterRes_rep_seq.fasta -i /scratch/group/hu-lab/meta-eukomics/salmon-quant/ -p $SLURM_CPUS_PER_TASK</span></span>
<span id="cb26-466"><a href="#cb26-466"></a><span class="in">```</span></span>
<span id="cb26-467"><a href="#cb26-467"></a></span>
<span id="cb26-468"><a href="#cb26-468"></a><span class="at">&gt; Indexing this data took 45 minutes (32 cores, 1 node) and 1.2 GB of memory</span></span>
<span id="cb26-469"><a href="#cb26-469"></a></span>
<span id="cb26-470"><a href="#cb26-470"></a><span class="in">```</span></span>
<span id="cb26-471"><a href="#cb26-471"></a><span class="in">salmon quant -i /scratch/group/hu-lab/meta-eukomics/salmon-quant/ -l A \</span></span>
<span id="cb26-472"><a href="#cb26-472"></a><span class="in">         -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz \</span></span>
<span id="cb26-473"><a href="#cb26-473"></a><span class="in">         -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \</span></span>
<span id="cb26-474"><a href="#cb26-474"></a><span class="in">         -p $SLURM_CPUS_PER_TASK --validateMappings -o /scratch/group/hu-lab/meta-eukomics/salmon-quant/quant</span></span>
<span id="cb26-475"><a href="#cb26-475"></a><span class="in">```</span></span>
<span id="cb26-476"><a href="#cb26-476"></a></span>
<span id="cb26-477"><a href="#cb26-477"></a><span class="at">&gt; At 32 cores (1 node), transcript counts took 3.5 hours and 4.2 GB of memory.</span></span>
<span id="cb26-478"><a href="#cb26-478"></a></span>
<span id="cb26-479"><a href="#cb26-479"></a>Read more here, especially on how to loop through samples: https://combine-lab.github.io/salmon/getting_started/#indexing-txome</span>
<span id="cb26-480"><a href="#cb26-480"></a></span>
<span id="cb26-481"><a href="#cb26-481"></a><span class="fu">## 11. Compile outputs</span></span>
<span id="cb26-482"><a href="#cb26-482"></a></span>
<span id="cb26-483"><a href="#cb26-483"></a><span class="ss">-   </span>Annotation from marferret: <span class="in">`/scratch/group/hu-lab/meta-eukomics/annotation/meta-eukomic_marferret_07082024.txt`</span> Column 1 is the contig ID name (qseqid) and the second ID is the match ID from the database (sseqid). These two columns need to be put into a new dataframe and called "TRANSCRIPTID" and "GENEID"</span>
<span id="cb26-484"><a href="#cb26-484"></a></span>
<span id="cb26-485"><a href="#cb26-485"></a><span class="ss">-   </span>For the GENEIDs, the "mftXXXXXXXXX" names correspond to pfam IDs in: <span class="in">`/scratch/group/hu-lab/marferret/data/MarFERReT.v1.1.1.best_pfam_annotations.csv.gz`</span></span>
<span id="cb26-486"><a href="#cb26-486"></a></span>
<span id="cb26-487"><a href="#cb26-487"></a><span class="sc">\*\*</span> Use <span class="in">`MarFERReT.v1.1.1.taxonomies.tab.gz`</span> to get the *tax id* and then line this up with <span class="in">`MarFERReT.v1.1.1.metadata.csv`</span> to get the actual taxonomy.</span>
<span id="cb26-488"><a href="#cb26-488"></a></span>
<span id="cb26-489"><a href="#cb26-489"></a>See <span class="in">`scripts/compile-metat-results.R`</span>. This script will output an R object called <span class="in">`tx_gene_KEY`</span>.</span>
<span id="cb26-490"><a href="#cb26-490"></a></span>
<span id="cb26-491"><a href="#cb26-491"></a><span class="fu">### 11.1 Transcipt counts</span></span>
<span id="cb26-492"><a href="#cb26-492"></a></span>
<span id="cb26-493"><a href="#cb26-493"></a>For obtaining transcript-level estimates from the salmon count files, we need to use the R library <span class="in">`tximport`</span>. Review <span class="co">[</span><span class="ot">the manual here</span><span class="co">](https://github.com/thelovelab/tximport?tab=readme-ov-file)</span>.</span>
<span id="cb26-494"><a href="#cb26-494"></a></span>
<span id="cb26-495"><a href="#cb26-495"></a>Salmon output should be <span class="in">`/meta-eukomics/salmon-quant/quant/quant.sf`</span></span>
<span id="cb26-496"><a href="#cb26-496"></a></span>
<span id="cb26-497"><a href="#cb26-497"></a>From the <span class="in">`compile-metat-results.R`</span> code, you can import this <span class="in">`tx_gene_KEY`</span> object to use in the <span class="in">`tximport`</span> estimation of TPMs. First, you need to run the command <span class="in">`tximport`</span>.</span>
<span id="cb26-498"><a href="#cb26-498"></a></span>
<span id="cb26-499"><a href="#cb26-499"></a>This should output a *txi* object called <span class="in">`txi_metat`</span> and then you can create a paired sample table.</span>
<span id="cb26-500"><a href="#cb26-500"></a></span>
<span id="cb26-501"><a href="#cb26-501"></a>See the Rscript <span class="in">`scripts/tximport_run.R`</span></span>
<span id="cb26-502"><a href="#cb26-502"></a></span>
<span id="cb26-503"><a href="#cb26-503"></a><span class="in">```</span></span>
<span id="cb26-504"><a href="#cb26-504"></a><span class="in">## Example:</span></span>
<span id="cb26-505"><a href="#cb26-505"></a><span class="in"># library(tximport)</span></span>
<span id="cb26-506"><a href="#cb26-506"></a><span class="in"># txi &lt;- tximport::tximport(files, type = "salmon", tx2gene = tx2gene_in)</span></span>
<span id="cb26-507"><a href="#cb26-507"></a><span class="in">```</span></span>
<span id="cb26-508"><a href="#cb26-508"></a></span>
<span id="cb26-509"><a href="#cb26-509"></a><span class="fu">### 11.2 Get TPMs &amp; Annotation information</span></span>
<span id="cb26-510"><a href="#cb26-510"></a></span>
<span id="cb26-511"><a href="#cb26-511"></a>See <span class="in">`scripts/format-output-tables.R`</span>. This takes the txi objects and uses the command <span class="in">`makeCountsFromAbundance()`</span> to generate a TPM file that represents the transcript-length corrected estimates.</span>
<span id="cb26-512"><a href="#cb26-512"></a></span>
<span id="cb26-513"><a href="#cb26-513"></a>Then the script imports the annotation file, merges it with the count information to create a large R object with TPMs and annotation information.</span>
<span id="cb26-514"><a href="#cb26-514"></a></span>
<span id="cb26-515"><a href="#cb26-515"></a><span class="fu">### 11.3 Reformat for hackathon!</span></span>
<span id="cb26-516"><a href="#cb26-516"></a></span>
<span id="cb26-517"><a href="#cb26-517"></a><span class="in">```</span></span>
<span id="cb26-518"><a href="#cb26-518"></a><span class="in">load("/scratch/group/hu-lab/meta-eukomics/counts_metat_df_annot.RData", verbose = TRUE)</span></span>
<span id="cb26-519"><a href="#cb26-519"></a><span class="in">glimpse(counts_metat_df_annot)</span></span>
<span id="cb26-520"><a href="#cb26-520"></a><span class="in">```</span></span>
<span id="cb26-521"><a href="#cb26-521"></a></span>
<span id="cb26-522"><a href="#cb26-522"></a><span class="fu">## Metatranscriptome run information</span></span>
<span id="cb26-523"><a href="#cb26-523"></a></span>
<span id="cb26-524"><a href="#cb26-524"></a>| Software     | Version  |</span>
<span id="cb26-525"><a href="#cb26-525"></a>|--------------|----------|</span>
<span id="cb26-526"><a href="#cb26-526"></a>| Fastqc       | 0.11.9   |</span>
<span id="cb26-527"><a href="#cb26-527"></a>| Trimmomatic  | 0.39     |</span>
<span id="cb26-528"><a href="#cb26-528"></a>| SortMeRNA    | 4.3.7    |</span>
<span id="cb26-529"><a href="#cb26-529"></a>| megahit      | 1.2.9    |</span>
<span id="cb26-530"><a href="#cb26-530"></a>| IDBA-Tran    | 1.1.3    |</span>
<span id="cb26-531"><a href="#cb26-531"></a>| quast        | 5.0.2    |</span>
<span id="cb26-532"><a href="#cb26-532"></a>| mmseqs2      | 13-45111 |</span>
<span id="cb26-533"><a href="#cb26-533"></a>| TransDecoder | 5.5.0    |</span>
<span id="cb26-534"><a href="#cb26-534"></a>| Salmon       | 1.7.0    |</span>
<span id="cb26-535"><a href="#cb26-535"></a>| Diamond      | 2.0.15   |</span>
<span id="cb26-536"><a href="#cb26-536"></a>|              |          |</span>
<span id="cb26-537"><a href="#cb26-537"></a></span>
<span id="cb26-538"><a href="#cb26-538"></a><span class="fu">#### Citations</span></span>
<span id="cb26-539"><a href="#cb26-539"></a></span>
<span id="cb26-540"><a href="#cb26-540"></a><span class="ss">-   </span><span class="sc">\[</span>fastqc<span class="sc">\]</span></span>
<span id="cb26-541"><a href="#cb26-541"></a></span>
<span id="cb26-542"><a href="#cb26-542"></a><span class="ss">-   </span><span class="sc">\[</span>trimmomatic<span class="sc">\]</span></span>
<span id="cb26-543"><a href="#cb26-543"></a></span>
<span id="cb26-544"><a href="#cb26-544"></a><span class="ss">-   </span>SortMeRNA: Kopylova E., Noe L. and Touzet H., "SortMeRNA: Fast and accurate filtering of ribosomal RNAs in metatranscriptomic data", Bioinformatics (2012), doi: 10.1093/bioinformatics/bts611.</span>
<span id="cb26-545"><a href="#cb26-545"></a></span>
<span id="cb26-546"><a href="#cb26-546"></a><span class="ss">-   </span><span class="sc">\[</span>megahit<span class="sc">\]</span></span>
<span id="cb26-547"><a href="#cb26-547"></a></span>
<span id="cb26-548"><a href="#cb26-548"></a><span class="ss">-   </span><span class="co">[</span><span class="ot">IDBA-Tran</span><span class="co">](https://academic.oup.com/bioinformatics/article/29/13/i326/191893)</span></span>
<span id="cb26-549"><a href="#cb26-549"></a></span>
<span id="cb26-550"><a href="#cb26-550"></a><span class="ss">-   </span>Salmon: Patro, R., Duggal, G., Love, M. I., Irizarry, R. A., &amp; Kingsford, C. (2017). Salmon provides fast and bias-aware quantification of transcript expression. Nature Methods.</span>
<span id="cb26-551"><a href="#cb26-551"></a></span>
<span id="cb26-552"><a href="#cb26-552"></a><span class="ss">-   </span>QUAST: Gurevich A, Saveliev V, Vyahhi N, Tesler G. QUAST: quality assessment tool for genome assemblies. Bioinformatics. 2013;29: 1072 1075. doi:10.1093/bioinformatics/btt086 , https://www.ncbi.nlm.nih.gov/pubmed/23422339</span>
<span id="cb26-553"><a href="#cb26-553"></a></span>
<span id="cb26-554"><a href="#cb26-554"></a><span class="fu"># eukrhythmic</span></span>
<span id="cb26-555"><a href="#cb26-555"></a></span>
<span id="cb26-556"><a href="#cb26-556"></a>Guidelines and notes on running the same set of samples through the <span class="co">[</span><span class="ot">eukrhythmic pipeline</span><span class="co">](https://eukrhythmic.readthedocs.io/en/latest/index.html)</span>. Running this on the TAMU HPRC with a conda environment.</span>
<span id="cb26-557"><a href="#cb26-557"></a></span>
<span id="cb26-558"><a href="#cb26-558"></a>First create a conda environment specific for eukrhythmic. <span class="co">[</span><span class="ot">Learn more about how to manage these environments here.</span><span class="co">](https://docs.conda.io/projects/conda/en/4.6.1/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands)</span></span>
<span id="cb26-559"><a href="#cb26-559"></a></span>
<span id="cb26-560"><a href="#cb26-560"></a><span class="in">```         </span></span>
<span id="cb26-561"><a href="#cb26-561"></a><span class="in">conda create -n eukrhythmic</span></span>
<span id="cb26-562"><a href="#cb26-562"></a></span>
<span id="cb26-563"><a href="#cb26-563"></a><span class="in"># Activate environment</span></span>
<span id="cb26-564"><a href="#cb26-564"></a><span class="in">conda activate eukrhythmic</span></span>
<span id="cb26-565"><a href="#cb26-565"></a></span>
<span id="cb26-566"><a href="#cb26-566"></a><span class="in"># Use HPRC system to ensure newest version of available Python is loaded</span></span>
<span id="cb26-567"><a href="#cb26-567"></a><span class="in">&gt; (eukrhythmic) module load GCCcore/12.3.0</span></span>
<span id="cb26-568"><a href="#cb26-568"></a><span class="in">&gt; (eukrhythmic) module load Python/3.11.3</span></span>
<span id="cb26-569"><a href="#cb26-569"></a><span class="in">```</span></span>
<span id="cb26-570"><a href="#cb26-570"></a></span>
<span id="cb26-571"><a href="#cb26-571"></a>To check what version of python you are automatically running, use <span class="in">`python --version`</span>.</span>
<span id="cb26-572"><a href="#cb26-572"></a></span>
<span id="cb26-573"><a href="#cb26-573"></a><span class="ss">-   </span>I could not get mamba configured correctly?</span>
<span id="cb26-574"><a href="#cb26-574"></a></span>
<span id="cb26-575"><a href="#cb26-575"></a><span class="in">```         </span></span>
<span id="cb26-576"><a href="#cb26-576"></a><span class="in">&gt; (eukrhythmic) conda install conda-forge::pyyaml</span></span>
<span id="cb26-577"><a href="#cb26-577"></a><span class="in">&gt; (eukrhythmic) conda install -c conda-forge python pandas</span></span>
<span id="cb26-578"><a href="#cb26-578"></a></span>
<span id="cb26-579"><a href="#cb26-579"></a><span class="in"># Install snakemake, but use mamba</span></span>
<span id="cb26-580"><a href="#cb26-580"></a><span class="in">&gt; (eukrhythmic) conda install -c conda-forge mamba</span></span>
<span id="cb26-581"><a href="#cb26-581"></a></span>
<span id="cb26-582"><a href="#cb26-582"></a><span class="in">mamba install -c conda-forge -c bioconda snakemake</span></span>
<span id="cb26-583"><a href="#cb26-583"></a><span class="in">```</span></span>
<span id="cb26-584"><a href="#cb26-584"></a></span>
<span id="cb26-585"><a href="#cb26-585"></a>To run eukrhythmic, activate the environment: <span class="in">`conda activate eukrhythmic`</span>.</span>
<span id="cb26-586"><a href="#cb26-586"></a></span>
<span id="cb26-587"><a href="#cb26-587"></a><span class="in">```</span></span>
<span id="cb26-588"><a href="#cb26-588"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>