[
  {
    "objectID": "main.html",
    "href": "main.html",
    "title": "Meta-eukomic",
    "section": "",
    "text": "SKH last updated June 2024\nLocation for raw files: /scratch/group/hu-lab/meta-eukomics/raw-data Individual R1 and R2 files are 2.9 and 2.7 G, respectively.\n\n\n\nCohen NR, Alexander H, Krinos AI, Hu SK, Lampe RH. Marine Microeukaryote Metatranscriptomics: Sample Processing and Bioinformatic Workflow Recommendations for Ecological Applications. Frontiers in Marine Science 2022; 9.\nKrinos AI, Cohen NR, Follows MJ, Alexander H. Reverse engineering environmental metatranscriptomes clarifies best practices for eukaryotic assembly. BMC Bioinformatics 2023; 24: 74.\n\n\n\n\nHigh performace computer (HPC) hosted by my University. This is the TAMU HPRC"
  },
  {
    "objectID": "main.html#background-reading",
    "href": "main.html#background-reading",
    "title": "Meta-eukomic",
    "section": "",
    "text": "Cohen NR, Alexander H, Krinos AI, Hu SK, Lampe RH. Marine Microeukaryote Metatranscriptomics: Sample Processing and Bioinformatic Workflow Recommendations for Ecological Applications. Frontiers in Marine Science 2022; 9.\nKrinos AI, Cohen NR, Follows MJ, Alexander H. Reverse engineering environmental metatranscriptomes clarifies best practices for eukaryotic assembly. BMC Bioinformatics 2023; 24: 74."
  },
  {
    "objectID": "main.html#working-environment",
    "href": "main.html#working-environment",
    "title": "Meta-eukomic",
    "section": "",
    "text": "High performace computer (HPC) hosted by my University. This is the TAMU HPRC"
  },
  {
    "objectID": "main.html#determine-assembly-groups",
    "href": "main.html#determine-assembly-groups",
    "title": "Meta-eukomic",
    "section": "2.1 1. Determine assembly groups",
    "text": "2.1 1. Determine assembly groups"
  },
  {
    "objectID": "main.html#trim-qc",
    "href": "main.html#trim-qc",
    "title": "Meta-eukomic",
    "section": "2.2 2. Trim & QC",
    "text": "2.2 2. Trim & QC\nInitial Fastqc\nCode for slurm script run on the HPC to run fastqc (fastqc.slurm). For this set of samples, it took 10 minutes and used 290 MB. CPU used: 00:12:27.\n\n\nCode\nmodule load FastQC/0.11.9-Java-11\n\nfastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001.fastq.gz\nfastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_001.fastq.gz\n\n\nIn order to look at the output .html files, they need to be opened locally.\n\n\nCode\nscp $HPRC-ADDRESS:/scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001_fastqc.html meta-eukomic/output-files/\n\n\nThen we need to trim the individual reads, removing any sequencing-based primers, etc. We can use the program, Trimmomatic for this. R1 reads are forward and R2 are reverse. The Trimmomatic software requires input reads and then output trimmed and unpaired reads (the latter of which are discarded). Another input file required is a list of the possible primers and adapters from sequencing, adapters-primers.fa.\nSlurm script, trim_fastqc.slurm. Below, trim parameter include:\n\nRemove adapters, found in adapters-primers.fa\nRemove leading low quality or N bases (below quality 3) (LEADING:3)\nRemove trailing low quality or N bases (below quality 3) (TRAILING:3)\nScan the read with a 4-base wide sliding window, cutting when the average quality per base drops below 10 (SLIDINGWINDOW:4:10)\nDrop reads shorter than 50 bases long (MINLEN:50)\n\n\n\nCode\nmodule load Trimmomatic/0.39-Java-11\n\njava -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar PE /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_001.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_001.fastq.gz  /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_unpaired.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_unpaired.fastq.gz ILLUMINACLIP:adapters-primers.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:10 MINLEN:50\n\n# \"$EBROOTTRIMMOMATIC/trimmomatic-0.39.jar\" note that this is specific to the HPRC system we are using\n\necho \"Trimmomtatic complete. Repeating fastqc\"\n\nmodule load FastQC/0.11.9-Java-11\n\nfastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz\nfastqc /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz"
  },
  {
    "objectID": "main.html#remove-ribosomal-rna",
    "href": "main.html#remove-ribosomal-rna",
    "title": "Meta-eukomic",
    "section": "2.3 3. Remove ribosomal RNA",
    "text": "2.3 3. Remove ribosomal RNA\nSortmerna installation guidelines and usage can be found here.\nOn the TAMU HPRC, this is where we needed to make a conda environment to run this.\n\n\nCode\n# Load anaconda\nmodule load Anaconda3/2022.05\n\n# modify bioconda config for sortmeRNA\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\n\nSearch for sortmerna using conda:\n\n\nCode\nconda search sortmerna\n\n\nCreate a conda environment specific for sortmerna, activate it, and install it.\n\n\nCode\nconda create --name sortmerna_env\nconda activate sortmerna_env\nconda install sortmerna\n\n\nAnswer “yes” (Y) to installation questions. Now when you run SortMeRNA, you need to activate this conda environment and execute your code. The next step is to download the databases to use for this program.\n\nSortMeRNA databases\nSeparately, you need to download the databases to “align” and check the sequences for ribosomal RNAs.\nInstructions for downloading version 4:\n\n\nCode\n# Move to the location you want your rRNA databases stored\ncd /scratch/group/hu-lab/meta-eukomics/ \n\n# Download from github release \nwget https://github.com/biocore/sortmerna/releases/download/v4.3.4/database.tar.gz\n\n# Make new directory for this and un-zip downloaded file\nmkdir rRNA_databases_v4\ntar -xvf database.tar.gz -C rRNA_databases_v4\n\n\n\n\nRun SortMeRNA\nIn your slurm script, activate conda, and then the sortmerna environment:\n\n\nCode\n# Load anaconda\nmodule load Anaconda3/2022.05\nconda activate sortmerna_env\n\nmkdir /scratch/group/hu-lab/meta-eukomics/rRNA-sort\n\nsortmerna -ref /scratch/group/hu-lab/meta-eukomics/rRNA_databases_v4/smr_v4.3_sensitive_db.fasta \\\n-reads /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz \\\n-reads /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \\\n-workdir /scratch/group/hu-lab/meta-eukomics/rRNA-sort/\n-fastx --paired_in --out2 --threads $SLURM_CPUS_PER_TASK\n\n\npaired_in: The option ‘paired_in’ is optimal for users who want all reads in the other.fasta file to be non-rRNA. However, there are small chances that reads which are non-rRNA will also be put into the aligned.fasta file.\nSince the SortmeRNA tool is optimitized to take things that are aligned with the rRNA databases and put them in a file called “aligned”, then we need to use the other.fasta output file.\nHow do I properly run sortmerna? https://github.com/sortmerna/sortmerna/issues/333"
  },
  {
    "objectID": "main.html#assembly",
    "href": "main.html#assembly",
    "title": "Meta-eukomic",
    "section": "2.4 4. Assembly",
    "text": "2.4 4. Assembly\nThe next step is to take all the sequenced reads and bring them together to make longer, more continuous sequences, called contigs. Here, we will use two assemblers and combine the results. Each one is built slightly differently.\n\nMEGAHIT (assembly 1)\nWe will first use megahit. To save the assemblies separately, make a new assembly output file in your working scratch space. mkdir /scratch/group/hu-lab/meta-eukomics/assembly\nThe megahit command below, outputs contigs in the new assembly directory, only keeps reads longer than 100 bps, and uses the megahit preset for lots of diversity in a sample (meta-large).\nMegahit uses multiple k-mer strategy, and we can set the min and max k. In order to reduce the complexity of the de Bruijin graph, a kmin size of 25 and higher (like 27) is better.\nSee slurm script: megahit-assembly.slurm\n\n\nCode\nmodule load GCCcore/11.2.0\nmodule load MEGAHIT/1.2.9\n\nmegahit -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz -o /scratch/group/hu-lab/meta-eukomics/assembly/ --min-contig-len 1000 --presets meta-large --num-cpu-threads 32\n\n\nWith the above settings, megahit recovered 31,331 contigs, total 44610184 bp, min 1000 bp, max 10674 bp, avg 1423 bp, N50 1391 bp. And this took about 10 hours.\nOn the HPC, this was run on 1 node, 4 cores per node, and it used 18.5 GBs of memory.\nMegahit assembly location: /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa\nOptional: Visualize your megahit assembly\nWhen megahit assembly is complete, use this option to visualize it: https://github.com/voutcn/megahit/wiki/Visualizing-MEGAHIT’s-contig-graph\n\n\nIDBA-Tran\nIDBA-tran is another de novo assembler. Uses local assembly to reconstruct missing kmers in low-expressed transcripts.\nSee script: idba-assembly.slurm to run assembly with minimum kmer at 20 and max kmer at 50 with a 5 step increment of kmer.\n\n\nCode\necho \"unzip files\"\ngunzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R*_trimmed.fastq.gz\n\nmodule load GCC/8.2.0-2.31.1 \nmodule load IDBA-UD/1.1.3\n\n# Convert fastq R1 and R2 files into a single 'interleaved` fastq files\nfq2fa --merge --filter /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq /scratch/group/hu-lab/meta-eukomics/assembly/merged-PE-for-idba.fa\n\n# Run assembly\nidba_tran -r /scratch/group/hu-lab/meta-eukomics/assembly/merged-PE-for-idba.fa -o /scratch/group/hu-lab/meta-eukomics/assembly/idba-out --mink 20 --maxk 50 --step 5 --num_threads 16\n\n# Make sure fastq files are re-zipped:\ngzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq\ngzip /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq\n\n\nUsing 8 cores, the IDBA-tran assembly took about 23 hours and used 130 GB of memory.\nThe IDBA-tran output includes separation by k-mer length. So there are multiple “contig-X.fa” files. Where contig-25.fa is the output contigs at k-mer = 25. The IDBA program determines which one is best and then puts this into the final contig.fa file. Output: /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa"
  },
  {
    "objectID": "main.html#evaluate-assemblies",
    "href": "main.html#evaluate-assemblies",
    "title": "Meta-eukomic",
    "section": "2.5 5. Evaluate assemblies",
    "text": "2.5 5. Evaluate assemblies\n\nQUAST\nQUAST stands for QUality ASsessment Tool and it is a tool for evaluating assemblies. Not all tools for evaluating assemblies will work, as most are built for metagenomics or require a reference genome. In this case, we do not have a reference genome.\nFirst for the IDBA output:\n\n\nCode\nmodule load GCC/9.3.0\nmodule load OpenMPI/4.0.3\nmodule load QUAST/5.0.2-Python-3.8.2\n\nquast.py /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/contig.fa \\\n        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \\\n        -o /scratch/group/hu-lab/meta-eukomics/assembly/idba-out/ \\\n        --threads $SLURM_CPUS_PER_TASK\n\n\nThis was run on 1 node with 16 cores. It used 3.5 GB of memory in about 1 hour. 6:15 CPUs used.\nRepeat for the megahit output\n\n\nCode\nmodule load GCC/9.3.0\nmodule load OpenMPI/4.0.3\nmodule load QUAST/5.0.2-Python-3.8.2\n\nquast.py /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/final.contigs.fa \\\n        -1 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R1_trimmed.fastq.gz -2 /scratch/group/hu-lab/meta-eukomics/raw-data/HS039_S90_L004_R2_trimmed.fastq.gz \\\n        -o /scratch/group/hu-lab/meta-eukomics/assembly/megahit-output/ \\\n        --threads $SLURM_CPUS_PER_TASK\n\n\n\nInterpret QUAST\nDownload files locally from:\n\nPDF files: meta-eukomics/assembly/*-out/basic_stats/*.pdf\nUse an ICARUS html viewer: meta-eukomics/assembly/*-out/icarus*\nBasic read stats: meta-eukomics/assembly/*-out/reads_stats/reads_report.tsv"
  },
  {
    "objectID": "main.html#metatranscriptome-run-information",
    "href": "main.html#metatranscriptome-run-information",
    "title": "Meta-eukomic",
    "section": "2.6 Metatranscriptome run information",
    "text": "2.6 Metatranscriptome run information\n\n\n\nSoftware\nVersion\n\n\n\n\nFastqc\n0.11.9\n\n\nTrimmomatic\n0.39\n\n\nSortMeRNA\n4.3.7\n\n\nmegahit\n1.2.9\n\n\nIDBA-Tran\n1.1.3\n\n\nquast\n5.0.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCitations\n\n[fastqc]\n[trimmomatic]\nSortMeRNA: Kopylova E., Noe L. and Touzet H., “SortMeRNA: Fast and accurate filtering of ribosomal RNAs in metatranscriptomic data”, Bioinformatics (2012), doi: 10.1093/bioinformatics/bts611.\n[megahit]\nIDBA-Tran"
  }
]